{
  "summary": {
    "model": "llama-3.1-8B",
    "total_papers": 100,
    "correct_predictions": 62,
    "accuracy": 62.0,
    "confusion_matrix": [
      [
        38,
        38
      ],
      [
        0,
        24
      ]
    ],
    "stats": {
      "Reject": {
        "total": 76,
        "recall": 50.0,
        "precision": 100.0
      },
      "Accept": {
        "total": 24,
        "recall": 100.0,
        "precision": 38.70967741935484
      }
    }
  },
  "results": [
    {
      "paper_id": "HygcdeBFvr",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper addresses a novel and challenging problem in singing voice generation, which is to generate singing voices without pre-assigned scores and lyrics.\n2. The authors propose a pipeline to tackle this new task, which involves source separation, transcription models, adversarial networks, and customized metrics for evaluation.\n3. The paper provides a clear and well-structured presentation of the problem, methodology, and results.\n4. The authors have made significant efforts to address the concerns and suggestions raised by the reviewers, which demonstrates their commitment to improving the paper.\n\nWeaknesses:\n\n1. The evaluation of the proposed method is still limited, and the authors rely heavily on objective metrics, which may not fully capture the subjective aspects of singing voice generation.\n2. The comparison with other methods, such as MIDI-based generation baselines, is not provided, which makes it difficult to assess the novelty and effectiveness of the proposed approach.\n3. Some of the reviewer comments raised concerns about the clarity and accuracy of certain statements, which the authors have addressed in their responses.\n4. The paper could benefit from a more detailed discussion of the limitations and potential applications of the proposed method.\n\nBased on these strengths and weaknesses, I conclude that the paper has made significant progress in addressing the novel problem of singing voice generation without pre-assigned scores and lyrics. However, the evaluation and comparison with other methods are still limited, and the paper could benefit from further refinement and clarification.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "HygqFlBtPS",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper proposes two regularizers that can be used to train neural networks that yield convex relaxations with tighter bounds, which is a significant contribution to the field of adversarial robustness.\n2. The experiments demonstrate that the proposed regularizations result in tighter certification bounds than non-regularized baselines, which is a promising result.\n3. The authors have addressed several concerns raised by the reviewers, including clarifying the mechanism of their regularizer, providing additional experimental results, and revising the paper to improve its clarity and coherence.\n\nWeaknesses:\n\n1. The analysis section is still somewhat confusing, and the authors could benefit from providing more intuitive explanations of their regularizers and how they work.\n2. The experimental results, while promising, are not entirely convincing due to the lack of certain baselines, such as the optimal convex relaxation method.\n3. The authors could have done a better job of addressing the concerns raised by Reviewer 2, particularly with regards to the theoretical justification of their regularizer and the potential limitations of their approach.\n\nOverall, I believe that the paper has made significant progress in addressing the concerns raised by the reviewers, and the authors have provided a clear and concise response to the feedback. However, I still have some reservations about the paper's overall quality and impact.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "HkgU3xBtDS",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have reached the following conclusion:\n\nThe paper is poorly written, lacks clarity, and has numerous grammatical issues. The abstract is unclear, and the author's attempt to explain the research is unsuccessful. The paper also lacks references, which is a fundamental aspect of academic writing. The reviewer comments from all three reviewers highlight these issues, and the author's responses do not adequately address them.\n\nMoreover, the paper's contribution is not clearly stated, and the proposed method is not well-explained. The author's response to Reviewer 1's comment about the lack of references is particularly concerning, as it suggests that the author is unaware of the importance of proper citation and referencing in academic writing.\n\nThe paper's technical content is also questionable. The author's response to Reviewer 3's comment about the lack of mathematical definitions and the unclear algorithm boxes suggests that the paper's technical aspects are not well-developed.\n\nGiven the severity of these issues, I believe that the paper is not suitable for publication in a top-tier conference. The author's responses to the reviewer comments do not demonstrate a sufficient understanding of academic writing and publishing standards.\n\nHowever, I also believe that the author has the potential to improve the paper with proper guidance and feedback. The author's responses suggest a willingness to learn and improve, which is a positive sign.\n\nTherefore, I recommend that the paper be rejected for publication in its current form. However, I suggest that the author be given the opportunity to revise and resubmit the paper after addressing the issues mentioned above.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "H1xzdlStvB",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper proposes a novel approach to reduce training time by employing a multilevel optimization approach that utilizes multiple precisions, including low-precision fixed-point representations.\n2. The authors demonstrate that their approach, MuPPET, achieves significant training time speedup (1.28Ã—) with no loss in accuracy compared to full-precision training.\n3. The paper provides a clear and concise introduction to the problem and the proposed solution.\n4. The authors have addressed most of the reviewer comments and provided additional details to clarify their approach.\n\nWeaknesses:\n\n1. The reviewer comments highlight several concerns regarding the clarity and completeness of the paper. Reviewer 1 and Reviewer 3 express concerns about the motivation behind the switching mechanism, and Reviewer 2 points out that the proposed approach does not match the description in the paper.\n2. The paper lacks a clear and concise statement of the novel contribution in the introduction.\n3. The authors have not provided a thorough explanation of the quantization scheme, and the notation used in the paper is not clear.\n4. The paper does not provide a clear comparison with existing state-of-the-art methods, and the results are not superior enough compared to [2].\n5. The authors have not provided a thorough analysis of the training and validation curves, which is a common practice in the field.\n\nAuthor Response:\n\nThe authors have addressed most of the reviewer comments and provided additional details to clarify their approach. However, some concerns remain:\n\n1. The authors have not provided a clear explanation of the motivation behind the switching mechanism, and the notation used in the paper is still unclear.\n2. The authors have not provided a thorough comparison with existing state-of-the-art methods, and the results are still not superior enough compared to [2].\n3. The authors have not provided a thorough analysis of the training and validation curves.\n\nConclusion:\n\nBased on the strengths and weaknesses of the paper, I recommend that the paper be accepted for publication, but with some minor revisions to address the concerns mentioned above. The authors have made significant contributions to the field by proposing a novel approach to reduce training time, and the paper has the potential to be a high-quality contribution to the conference.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "rJxe3xSYDS",
      "source": "ICLR 2020",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper proposes a novel approach to negative sampling for extreme classification, which is a significant problem in machine learning.\n2. The authors provide a clear and concise explanation of their method, including a mathematical proof of its optimality.\n3. The experimental results show that the proposed method outperforms several competitive baselines in terms of training time.\n4. The authors acknowledge the limitations of their approach and provide a clear discussion of the related work.\n\nWeaknesses:\n\n1. The paper lacks a comprehensive discussion of the related work, particularly in the context of extreme classification.\n2. The authors do not provide a thorough comparison of their method with other state-of-the-art approaches, such as Slice and DiSMEC.\n3. The experimental evaluation is limited to two datasets, and the authors do not provide a thorough analysis of the results.\n4. The paper does not discuss the potential limitations of the proposed method, such as its applicability to multi-label classification.\n\nReviewer comments and author responses:\n\n1. Reviewer 1 provides a positive review, highlighting the clarity and approachability of the paper.\n2. Reviewer 2 raises several concerns, including the lack of comprehensive related work and the limited experimental evaluation.\n3. Reviewer 3 provides a mixed review, highlighting the strengths of the proposed method but also criticizing the experimental evaluation and the lack of comparison with other state-of-the-art approaches.\n\nAuthor responses:\n\n1. The authors acknowledge the limitations of their approach and provide a clear discussion of the related work.\n2. They respond to the concerns raised by Reviewer 2 and Reviewer 3, providing additional information and clarification.\n3. They also provide a clear explanation of the differences between their approach and other methods, such as sampled softmax.\n\nFinal Decision: Accept\n\nWhile the paper has some weaknesses, particularly in the discussion of related work and the experimental evaluation, the authors have addressed many of the concerns raised by the reviewers. The proposed method is novel and has the potential to make a significant contribution to the field of extreme classification. The authors have also provided a clear and concise explanation of their approach, including a mathematical proof of its optimality. Overall, I believe that the paper is worthy of publication in a top-tier conference."
    },
    {
      "paper_id": "H1livgrFvr",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel out-of-distribution detection method, MALCOM, which is an interesting and timely contribution to the field.\n2. The authors provide a clear and concise explanation of their method and its motivation.\n3. The paper presents experimental results on several benchmarks with different deep neural network architectures, which supports their claim.\n4. The authors have addressed some of the reviewer comments and concerns in their response.\n\n**Weaknesses:**\n\n1. The comparison in the main paper is somewhat unfair, as mentioned by Reviewer 1. The authors should have compared their method with the vanilla version of the Mahalanobis method, which is a more direct comparison.\n2. The performance of the replication of the prior method is far lower than reported, which raises concerns about the accuracy of the results.\n3. Reviewer 2 points out that the justification for the strict constraints is not enough, and the authors should have compared their method with existing methods that are not so tightly constrained.\n4. Reviewer 3 is skeptical about the effectiveness of the proposed method and suggests that the experiments could have been done in a more complex setting.\n\n**Author Response:**\n\nThe authors have addressed some of the reviewer comments and concerns in their response, but not all of them. They have provided additional experiments and results to support their claim, but the comparison with existing methods that are not so tightly constrained is still lacking.\n\n**Conclusion:**\n\nBased on the strengths and weaknesses of the paper, as well as the author response, I believe that the paper has potential but requires further revisions to address the concerns raised by the reviewers. The authors should:\n\n1. Revise the comparison in the main paper to make it more fair and direct.\n2. Provide more accurate results for the replication of the prior method.\n3. Compare their method with existing methods that are not so tightly constrained.\n4. Address the concerns raised by Reviewer 3 about the effectiveness of the proposed method.\n\nIf the authors can address these concerns and revise the paper accordingly, I would recommend accepting it for publication.\n\n**Final Decision:** Accept"
    },
    {
      "paper_id": "rklj3gBYvH",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper targets an important and interesting topic in meta-learning, addressing the scalability issue of certain meta-learning frameworks.\n2. The proposed method, NORML, is well-defined and has a clear architecture.\n3. The authors provide a detailed comparison with MAML and an ablation study on Omniglot.\n\n**Weaknesses:**\n\n1. The paper lacks novelty, as it is a fairly incremental variation compared to the Meta-Learner LSTM (Ravi & Larochelle).\n2. The authors do not provide a direct comparison with Meta-Learner LSTM, which is a major limitation.\n3. The experimental results are not convincing, as the authors do not show the results from Sun et al. (2019) and use a different base learner for the Mini-ImageNet experiment.\n4. The paper has several grammatical mistakes, and the writing needs a massive overhaul.\n5. The authors make inaccurate descriptions of prior work, such as stating that Meta-Learner LSTM requires an enormous number of parameters.\n\n**Reviewer Comments:**\n\n1. Reviewer 1 raises several concerns, including the lack of direct comparison with Meta-Learner LSTM, the limited experimental results, and the inaccurate descriptions of prior work.\n2. Reviewer 2 highlights the need for a massive overhaul of the writing, grammatical mistakes, and inconsistent citations.\n3. Reviewer 3 believes the submission should be rejected due to limited novelty, missing baselines, limited applicability, and inaccurate descriptions of prior work.\n\n**Author Response:**\n\nUnfortunately, there is no author response available, which makes it difficult to address the concerns raised by the reviewers.\n\n**Conclusion:**\n\nBased on the detailed analysis, I conclude that the paper has several significant weaknesses, including lack of novelty, limited experimental results, and inaccurate descriptions of prior work. While the paper targets an important topic in meta-learning, the authors do not provide a strong enough case for the proposed method, NORML. Therefore, I recommend rejecting the paper for publication.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "SJxpsxrYPS",
      "source": "ICLR 2020",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I conclude that the paper should be accepted for publication.\n\nHere's my detailed reasoning:\n\n1. **Novelty and contribution**: The paper presents a novel approach to learning disentangled representations using a progressive learning strategy. The authors demonstrate that their method can improve disentanglement in comparison to existing works on two benchmark datasets. The contribution is significant, and the paper provides a clear and concise explanation of the method.\n2. **Methodological soundness**: The paper presents a well-defined and well-motivated method for learning disentangled representations. The authors provide a clear explanation of the progressive learning strategy and its implementation. The method is based on a sound theoretical foundation, and the authors provide a thorough analysis of the results.\n3. **Experimental evaluation**: The paper presents a thorough experimental evaluation of the method on two benchmark datasets. The authors provide a clear and concise description of the experimental setup, and the results are well-presented and easy to understand. The authors also provide a comparison with existing methods, which is essential for evaluating the novelty and contribution of the paper.\n4. **Addressing reviewer comments**: The authors have addressed most of the reviewer comments, including the concerns raised by Reviewer 1, Reviewer 2, and Reviewer 3. The authors have provided additional experiments, clarifications, and discussions to address the concerns, which demonstrates their commitment to improving the paper.\n5. **Quality of writing and presentation**: The paper is well-written, and the authors have provided a clear and concise explanation of the method and results. The paper is well-organized, and the authors have used proper notation and formatting.\n\nHowever, there are a few areas where the paper could be improved:\n\n1. **Ablation studies**: While the authors have provided some ablation studies, they could be more comprehensive. The authors could investigate the effect of different implementation strategies, such as the fade-in strategy, and provide more detailed results.\n2. **Comparison with existing methods**: While the authors have provided a comparison with existing methods, they could be more thorough. The authors could provide a more detailed comparison with the VLAE model and other state-of-the-art methods.\n3. **Discussion and conclusion**: While the authors have provided a clear and concise explanation of the method and results, they could provide a more detailed discussion and conclusion. The authors could discuss the implications of the results and provide more insights into the future work.\n\nOverall, I believe that the paper presents a significant contribution to the field of disentangled representation learning, and the authors have provided a thorough and well-presented evaluation of the method. With some minor revisions to address the areas mentioned above, I believe that the paper is ready for publication.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "BJg8_xHtPr",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I conclude that the paper should be accepted for publication.\n\nHere's my detailed reasoning:\n\n1. **Improvement in writing and clarity**: The authors have made significant efforts to address the reviewers' concerns about the paper's writing and clarity. They have rewritten and reorganized substantial parts of the paper, adopted standard GQN notation, and clarified notations and descriptions. This improvement in writing and clarity makes the paper more accessible to a broader audience.\n2. **Addressing reviewer concerns**: The authors have responded to all reviewer comments, addressing concerns about notation, consistency, and readability. They have also provided additional explanations and clarifications, demonstrating a good understanding of the reviewers' feedback.\n3. **Additional experiments and results**: The authors have added two new experiment results in the Appendix, which demonstrate the generalization performance of ROOTS in different settings. This additional evidence strengthens the paper's claims and provides more confidence in the results.\n4. **Positioning in the literature**: The authors have added a paragraph in Section 1 to clarify the different settings between their proposed work and existing works. They have also added a significant amount of discussion in the Related Works section, including relevant citations. This improved positioning in the literature demonstrates the authors' understanding of the paper's contributions and limitations.\n5. **Addressing concerns about model complexity and ablation studies**: The authors have provided explanations and justifications for their model complexity and the lack of ablation studies. They have also acknowledged the importance of ablation studies and have started running experiments to investigate the impact of different components on the results.\n6. **Minor issues**: The authors have addressed all minor issues pointed out by the reviewers, including typos, notation errors, and inconsistencies.\n\nWhile the paper still has some limitations and areas for improvement, the authors have made significant efforts to address the reviewers' concerns and strengthen the paper. The additional experiments, clarifications, and positioning in the literature demonstrate the authors' commitment to improving the paper and making it more accessible to the community.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "HyeKcgHFvS",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\nStrengths:\n\n1. The paper presents a novel approach to training Gaussian Mixture Models (GMMs) using Stochastic Gradient Descent (SGD) in high-dimensional spaces.\n2. The authors propose three novel ideas: minimizing an upper bound to the GMM log likelihood, a new regularizer to prevent SGD from converging to pathological local minima, and a method for enforcing constraints inherent to GMM training when using SGD.\n3. The paper provides a publicly available TensorFlow implementation, which is a significant contribution.\n\nWeaknesses:\n\n1. Reviewer 1 and 2 express concerns about the incremental nature of the work, lack of understanding of the long history of online EM, and ad-hoc approach to online EM.\n2. Reviewer 2 points out that the results and presentation are not at the level suitable for publication, and the experimental evaluation is not convincing.\n3. Reviewer 3 notes that the main contribution is to describe a simple method to learn GMMs from random initialization, but the method has limitations, such as only successful results with diagonal covariance matrices.\n4. The authors' responses to the reviewers' comments are generally satisfactory, but some points, such as the motivation for the maximization in eq. (2) and the requirement Î£_{i,j} >=0, are still unclear.\n\nConcerns:\n\n1. The paper's focus on SGD for GMMs in high-dimensional spaces is an important contribution, but the incremental nature of the work and lack of understanding of online EM history raise concerns about the novelty and significance of the contribution.\n2. The experimental evaluation is limited to datasets with at most 28x28 dimensions, which is not high-dimensional according to the authors' own definition.\n3. The authors' responses to the reviewers' comments are generally satisfactory, but some points, such as the motivation for the maximization in eq. (2) and the requirement Î£_{i,j} >=0, are still unclear.\n\nBased on these observations and concerns, I recommend the following:\n\nFinal Decision: Reject\n\nThe paper presents a novel approach to training GMMs using SGD in high-dimensional spaces, but the incremental nature of the work, lack of understanding of online EM history, and limited experimental evaluation raise concerns about the novelty and significance of the contribution. While the authors' responses to the reviewers' comments are generally satisfactory, some points are still unclear. Therefore, I recommend rejecting the paper for publication in a top-tier conference."
    },
    {
      "paper_id": "HygkpxStvr",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths of the paper:\n\n1. The problem statement is interesting and relevant to the field of robot learning and manipulation.\n2. The authors propose a novel approach to weakly-supervised trajectory segmentation, which is a challenging problem.\n3. The paper provides a clear and concise explanation of the method and its application to various environments.\n\nWeaknesses of the paper:\n\n1. The reviewer comments highlight several concerns, including the lack of novelty in the approach, limited scope, and poor experimental design.\n2. The classification results are low, and the authors' response does not fully address the concerns raised by the reviewers.\n3. The paper lacks thorough comparisons with relevant baselines, including fully-supervised oracle methods and unsupervised clustering methods.\n4. The authors' response to R1's comment about the dataset requirements for the approach is unclear and does not provide a clear explanation of the limitations of the method.\n\nBased on the reviewer comments and author responses, I agree with the concerns raised by the reviewers. While the paper presents an interesting problem and approach, the experimental design and results are not convincing, and the authors' responses do not fully address the concerns.\n\nHowever, I also agree with the authors that the problem statement is important and relevant to the field. The authors' response to R2's comment about the novelty of the approach is also valid, as the approach is a good application of the MIL approach, but the novelty is not high.\n\nConsidering all the information provided, I conclude that the paper has some potential but requires significant revisions to address the concerns raised by the reviewers. Therefore, I recommend:\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "ryxB2lBtvH",
      "source": "ICLR 2020",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the research paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper presents a novel approach to multi-agent coordination by learning to coordinate skills in isolation and then combining them to solve complex tasks.\n2. The proposed method, Skill Behavior Diversification (SBD), is well-motivated and has a clear theoretical foundation.\n3. The empirical results demonstrate the effectiveness of the proposed method in solving challenging collaborative control tasks.\n4. The authors have addressed most of the reviewer concerns and provided additional experiments to support their claims.\n\nWeaknesses:\n\n1. The paper assumes that the skills are pre-trained separately, which may not be realistic in many scenarios.\n2. The method relies on specifying the subtasks in advance, which may limit its applicability to tasks with complex or dynamic subtasks.\n3. The paper does not provide a thorough comparison with other multi-agent methods, which may make it difficult to evaluate the novelty and impact of the proposed method.\n4. Some of the reviewer concerns, such as the high variance in performance and the inconsistent notations, have not been fully addressed.\n\nBased on these strengths and weaknesses, I would recommend accepting the paper for publication, but with some minor revisions to address the remaining concerns.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "BJlA6eBtvH",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\nStrengths:\n\n1. The paper addresses an important problem in machine learning, namely catastrophic forgetting in neural networks.\n2. The proposed Differentiable Hebbian Consolidation (DHC) model is a novel and interesting approach to tackle this problem.\n3. The authors provide a clear and concise explanation of their method and its motivation.\n4. The experimental results show that DHC outperforms baseline methods on several benchmarks.\n\nWeaknesses and concerns:\n\n1. Reviewer 1 and Reviewer 4 have concerns about the empirical evaluation, suggesting that the results are not convincing, especially when compared to other methods.\n2. Reviewer 2 has questions and suggestions about the notation, equations, and motivation of the DHC model.\n3. Reviewer 3 has some minor concerns about the experimental section and suggests additional experiments.\n4. The authors' responses to the reviewers' comments are generally satisfactory, but some points, such as the comparison to other CLS-based approaches, are not fully addressed.\n\nConsidering the strengths and weaknesses, I believe that the paper has potential but requires further improvement. The authors need to address the concerns raised by the reviewers, particularly the empirical evaluation and comparison to other methods. Additionally, the paper could benefit from more detailed explanations and clarifications, such as the notation and equations.\n\nFinal Decision: Accept with minor revisions"
    },
    {
      "paper_id": "rkgfdeBYvH",
      "source": "ICLR 2020",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I conclude that the paper should be accepted for publication.\n\nHere's my detailed reasoning:\n\nStrengths of the paper:\n\n1. The paper provides a thorough theoretical analysis of the effect of activation functions on the training of overparametrized neural networks. The authors examine the behavior of the eigenvalues of the Gram matrix, which is crucial to the convergence rate of training in the lazy regime.\n2. The paper shows that for non-smooth activations, the minimum eigenvalue of the Gram matrix is large under separation assumptions on the data, improving on prior work.\n3. For smooth activations, the authors show that the minimum eigenvalue can be exponentially small (or even 0 in case of polynomials) if the data has low-dimensional structure or the network is sufficiently deep.\n4. The authors experimentally validate the observations on synthetic data, and the results agree with the theory.\n5. The paper is well-written, self-contained, and well-referenced.\n\nWeaknesses of the paper:\n\n1. The appendix is too long, which can make it difficult for readers to navigate.\n2. Some of the results in the appendix are not clearly connected to the main paper.\n3. The paper could benefit from a more focused presentation, with a clearer roadmap of the appendix.\n\nAuthor responses:\n\nThe authors have addressed the concerns raised by the reviewers, including:\n\n1. Shortening the appendix and adding a table of contents to make it easier to navigate.\n2. Improving the organization of the appendix and highlighting the main techniques and ideas.\n3. Providing more explanations in some proofs to improve readability.\n\nMinor concerns:\n\nThe authors have also addressed minor concerns raised by the reviewers, including:\n\n1. Correcting errors in the paper, such as the name of the authors of Du et al. 2019a.\n2. Clarifying assumptions and notation.\n\nOverall, the paper provides a significant contribution to the field of deep learning theory, and the authors have addressed the concerns raised by the reviewers. While the paper could benefit from further improvements in presentation and organization, it is well-written and well-referenced, and the results are significant and interesting.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "BJe55gBtvH",
      "source": "ICLR 2020",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I conclude that the paper should be accepted for publication.\n\nHere's my detailed reasoning:\n\nStrengths:\n\n1. **Originality**: The paper presents a novel connection between deep neural networks (DNNs) and Sharkovsky's Theorem from dynamical systems, which is a significant contribution to the field.\n2. **Technical soundness**: The authors provide a thorough and technically sound analysis of the depth-width trade-offs for ReLU networks, leveraging the Sharkovsky Theorem to derive lower bounds on the width needed to represent periodic functions.\n3. **Clear exposition**: The paper is well-written, and the authors have made efforts to clarify the technical details and provide intuitive explanations.\n4. **Relevance**: The paper addresses an important open question in deep learning and approximation theory, providing a natural property of functions (periodic points) and deriving depth-width trade-offs based on it.\n\nWeaknesses:\n\n1. **Limited practical impact**: While the paper provides a significant theoretical contribution, its practical impact is limited, as the authors acknowledge that assessing the period of a function is a difficult problem.\n2. **Overemphasis on technical details**: Reviewer 3's comment suggests that the paper overloads with general theory before getting to the main point, which might make it less accessible to readers who are not familiar with dynamical systems.\n3. **Lack of empirical evaluation**: While the authors provide some experimental results, they are limited to a synthetic dataset, and it would be beneficial to see more extensive empirical evaluations to demonstrate the practical relevance of the paper's findings.\n\nAuthor responses:\n\nThe authors have addressed the reviewer comments effectively, providing additional explanations, examples, and experimental results. They have also restructured the paper to make it more accessible to readers who are not familiar with dynamical systems.\n\nFinal Decision: Accept\n\nThe paper presents a significant theoretical contribution to the field of deep learning and approximation theory, and the authors have addressed the reviewer comments effectively. While there are some limitations to the paper's practical impact and empirical evaluation, the strengths of the paper outweigh its weaknesses."
    },
    {
      "paper_id": "Hyg53gSYPB",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully reviewing the paper, the reviewer comments, and the author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper proposes a novel approach to defend against adversarial examples by using an encoder-assisted search in the latent coding space. This approach is an alternative to the Defence-GAN method, which is computationally expensive.\n2. The authors provide a clear and concise explanation of their method, and the paper is well-organized.\n3. The experimental results show that the proposed method is effective against various attacks, including white-box and black-box attacks.\n4. The authors have addressed most of the reviewer comments and concerns, and the revised paper is improved.\n\nWeaknesses:\n\n1. The paper relies heavily on the autoencoder's ability to detect adversarial samples, which can be susceptible to white-box attacks.\n2. The detection mechanism can be affected by the quality of the autoencoder, and the authors have not provided a clear explanation of how to ensure the latent distribution F(x) from the data and the prior p(z) are similar.\n3. The paper does not provide a clear comparison with state-of-the-art adversarial training defenses, such as PGD Adversarial Training and TRADES.\n4. The results on more complex datasets, such as CIFAR-10, are not provided, and the authors have not addressed this concern fully.\n\nBased on these strengths and weaknesses, I conclude that the paper has made significant improvements, but there are still some concerns that need to be addressed.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "BklhsgSFvB",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper proposes a novel multi-task learning framework that captures both general task dependency and data-specific task dependency, which is a significant contribution to the field.\n2. The authors provide a clear motivation for their approach, highlighting the limitations of existing methods that assume tasks are highly correlated.\n3. The paper presents a well-structured and organized framework, with a clear explanation of the proposed method and its components.\n4. The authors provide experimental results on several public datasets, demonstrating the effectiveness of their approach.\n\nWeaknesses:\n\n1. The paper suffers from grammatical mistakes and errors, which can make it difficult to follow the finer points of the arguments.\n2. The distinction between general task dependency and data-specific task dependency is not clearly explained, and the authors' response does not fully address this issue.\n3. The paper lacks a thorough comparison with existing methods, particularly those that also model task dependency.\n4. The authors' response to Reviewer 4's comments is inadequate, as they do not provide a clear discussion on how their proposal is different and better than recent works that were not cited.\n\nReviewer comments and author responses:\n\n1. Reviewer 1's comments highlight the need for improved presentation and clarity, particularly in the experimental section.\n2. Reviewer 2's comments suggest that the authors provide a stronger motivation for the proposed approach and clarify the use of attention in the method.\n3. Reviewer 3's comments point out that the authors' claim about most current multi-task learning frameworks relying on the assumption that tasks are highly correlated is not accurate.\n4. Reviewer 4's comments are critical, highlighting the authors' lack of awareness of prior work that models task relationships and their failure to provide a clear discussion on the differences and contributions of their approach.\n\nAuthor responses:\n\n1. The authors provide a clear explanation of the distinctions between their work and previous works, but their response to Reviewer 4's comments is still inadequate.\n2. The authors address some of the minor suggestions, but their response to Reviewer 2's comments is not fully satisfactory.\n\nBased on the above analysis, I conclude that the paper has some significant strengths, but it also suffers from several weaknesses and lacks a thorough comparison with existing methods. While the authors' response to reviewer comments is generally satisfactory, it does not fully address the critical issues raised by Reviewer 4.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "rJePwgSYwB",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper provides a novel analysis of the global convergence of gradient descent-ascent in the GAN setting, which is a significant contribution to the field.\n2. The authors provide a clear and concise explanation of their results, and the paper is well-written.\n3. The authors address several concerns raised by the reviewers, including the choice of discriminator class and the sample complexity of the algorithm.\n\nWeaknesses:\n\n1. The paper only considers a simplified version of the WGAN, with a quadratic discriminator and a one-layer generator. This may not be representative of the more complex GANs used in practice.\n2. The authors do not provide a clear explanation of how their results can be extended to more complex GANs, which is a significant limitation of the paper.\n3. Some reviewers have raised concerns about the simplicity of the discriminator class and the generator architecture, which may not be representative of the more complex models used in practice.\n\nReviewer comments:\n\n1. Reviewer 1 raises concerns about the simplicity of the discriminator class and the generator architecture, and suggests that the authors should consider more complex models.\n2. Reviewer 2 agrees that the analysis of gradient descent-ascent is a difficult problem, but suggests that the authors should consider more complex discriminators and generators.\n3. Reviewer 3 raises concerns about the simplicity of the discriminator class and the generator architecture, and suggests that the authors should provide more explanations about the error propagation in the gradient ascent step.\n\nAuthor responses:\n\n1. The authors address several concerns raised by the reviewers, including the choice of discriminator class and the sample complexity of the algorithm.\n2. The authors provide a clear explanation of their results and the limitations of their paper.\n\nBased on the strengths and weaknesses of the paper, as well as the reviewer comments and author responses, I conclude that the paper has some significant contributions to the field, but also has some limitations that need to be addressed.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "ryxB2lBtvH",
      "source": "ICLR 2020",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the research paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper presents a novel approach to multi-agent coordination by learning to coordinate skills in isolation and then combining them to solve complex tasks.\n2. The proposed framework is well-motivated and has a clear structure, making it easy to follow and understand.\n3. The authors provide a comprehensive evaluation of their method on various tasks, including manipulation and locomotion, and demonstrate its effectiveness compared to baseline methods.\n4. The authors address several concerns raised by the reviewers, including the use of DIAYN only as a baseline, the size of the latent skill embedding, and the high variance in performance.\n\nWeaknesses:\n\n1. The paper assumes that the skills are pre-trained in isolation, which may not be the case in many real-world scenarios.\n2. The authors do not provide a thorough analysis of the coordination problem between agents, which is a critical aspect of multi-agent reinforcement learning.\n3. The paper relies heavily on the DIAYN method for skill discovery, which may not be the most effective method for all tasks.\n4. The authors do not provide a clear explanation of how the meta-policy learns to coordinate the skills of different agents.\n\nBased on these strengths and weaknesses, I believe that the paper has made significant contributions to the field of multi-agent reinforcement learning and has the potential to be published in a top-tier conference.\n\nHowever, I also have some concerns that need to be addressed:\n\n1. The paper assumes that the skills are pre-trained in isolation, which may not be the case in many real-world scenarios. The authors should provide a more thorough analysis of this assumption and discuss potential ways to address it.\n2. The authors do not provide a clear explanation of how the meta-policy learns to coordinate the skills of different agents. The authors should provide more details on this aspect of the method.\n3. The paper relies heavily on the DIAYN method for skill discovery, which may not be the most effective method for all tasks. The authors should provide a more thorough evaluation of the method and discuss potential ways to improve it.\n\nTo address these concerns, I recommend that the authors:\n\n1. Provide a more thorough analysis of the assumption that skills are pre-trained in isolation and discuss potential ways to address it.\n2. Provide a clear explanation of how the meta-policy learns to coordinate the skills of different agents.\n3. Provide a more thorough evaluation of the DIAYN method and discuss potential ways to improve it.\n\nIf the authors can address these concerns, I believe that the paper has the potential to be published in a top-tier conference.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "Bkel6ertwS",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\n**Strengths:**\n\n1. The paper presents an interesting application of machine learning to predict DNA folding patterns using Recurrent Neural Networks (RNNs).\n2. The authors demonstrate the effectiveness of their approach using a bidirectional LSTM RNN model, which outperforms other models in predicting chromatin folding patterns.\n3. The paper explores the use of epigenetic features, such as ChIP-Seq data, to improve the prediction of DNA folding patterns.\n\n**Weaknesses and concerns:**\n\n1. **Lack of novelty:** Reviewer 3 raises concerns about the paper's similarity to previously published works, which are not cited. The authors respond by pointing out the differences between their work and existing papers, but this is not entirely convincing.\n2. **Methodological limitations:** Reviewer 1 and 3 raise concerns about the lack of methodological novelty and the limited evaluation of the models. The authors respond by adding more evaluation metrics, but this does not fully address the concerns.\n3. **Data and feature representation:** Reviewer 3 raises concerns about the unclear description of the data and feature representation. The authors respond by expanding the description, but some questions remain unanswered.\n4. **Generalizability:** Reviewer 1 raises concerns about the generalizability of the results to other Hi-C datasets and predictions based on other epigenetic features. The authors respond by stating that they did not test their models on other datasets due to biological reasons, but this does not fully address the concern.\n5. **Lack of discussion:** Reviewer 2 raises concerns about the lack of discussion on the choice of models and the advantage of using Neural Networks. The authors respond by expanding the discussion, but it is still not entirely clear why the LSTM model is preferred.\n\n**Author responses:**\n\nThe authors have responded to the reviewer comments, addressing some of the concerns and providing additional information. However, some questions remain unanswered, and the responses do not fully address the concerns raised by the reviewers.\n\n**Conclusion:**\n\nBased on the analysis, I conclude that the paper has some strengths, but also significant weaknesses and concerns. While the authors have made efforts to address the reviewer comments, some questions remain unanswered, and the paper's novelty and methodological rigor are still a concern.\n\n**Final Decision:** Reject\n\nThe paper's limitations and concerns outweigh its strengths, and it does not meet the standards of a top-tier conference. The authors should revise the paper to address the concerns raised by the reviewers and provide more convincing evidence of the paper's novelty and methodological rigor."
    },
    {
      "paper_id": "HkgU3xBtDS",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have reached the following conclusions:\n\n**Reasoning:**\n\n1. **Poor writing and clarity**: All three reviewers have highlighted the poor writing and lack of clarity in the paper. The abstract is particularly unclear, and the reviewers have struggled to understand the main contributions of the paper. This is a significant issue, as it makes it difficult for readers to understand and evaluate the research.\n2. **Lack of references**: The paper does not include any references, which is a fundamental aspect of academic writing. This omission makes it difficult to evaluate the paper's contributions in the context of existing research.\n3. **Inaccurate and unjustified statements**: Reviewer 2 has pointed out that the paper contains inaccurate and unjustified statements, which further undermines the paper's credibility.\n4. **Lack of clear contributions**: The paper's main contribution is not clearly stated, and the reviewers have struggled to understand how the proposed method improves upon existing approaches.\n5. **Author responses**: While the authors have acknowledged the reviewers' comments and expressed a willingness to improve their writing skills, their responses do not address the fundamental issues with the paper.\n\n**Conclusion:**\n\nGiven the significant issues with the paper's writing, clarity, and lack of references, I believe that it is not suitable for publication in a top-tier conference. The paper's poor quality and lack of clear contributions make it difficult to evaluate its contributions to the field.\n\n**Final Decision: Reject**\n\nThe paper requires significant revisions to address the fundamental issues mentioned above. The authors should focus on improving the writing, clarity, and accuracy of the paper, as well as including relevant references to establish the paper's contributions in the context of existing research."
    },
    {
      "paper_id": "rJxycxHKDS",
      "source": "ICLR 2020",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\nStrengths:\n\n1. The paper proposes a novel approach to unsupervised domain adaptation, which is a significant contribution to the field.\n2. The authors provide a clear and concise explanation of their method, and the paper is well-written and easy to follow.\n3. The experimental results show that the proposed method outperforms the baseline methods in some cases.\n4. The authors have addressed most of the reviewer comments and concerns in their response.\n\nWeaknesses and concerns:\n\n1. The paper lacks a thorough comparison with state-of-the-art domain adaptation methods, which is a significant limitation.\n2. The authors have not provided enough experimental results to support their claims, particularly in terms of hyperparameter sensitivity analysis and ablation studies.\n3. The paper does not provide a clear explanation for the behavior observed in Figure 4, which shows that the domains do not share parameters at the end of training.\n4. The authors have not addressed the issue of parameter sharing between domains, which is a critical aspect of domain adaptation.\n5. The paper lacks a clear discussion on the limitations of the proposed method and potential future work.\n\nBased on these observations and concerns, I would recommend that the paper be accepted for publication, but with some minor revisions to address the above issues. The authors have made a significant contribution to the field, and the paper has the potential to be a high-quality publication.\n\nHowever, to ensure that the paper meets the standards of a top-tier conference, I would recommend that the authors:\n\n1. Provide a more thorough comparison with state-of-the-art domain adaptation methods.\n2. Conduct more extensive experimental results, including hyperparameter sensitivity analysis and ablation studies.\n3. Provide a clear explanation for the behavior observed in Figure 4.\n4. Address the issue of parameter sharing between domains.\n5. Discuss the limitations of the proposed method and potential future work.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "SkluFgrFwH",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\nStrengths:\n\n1. The paper presents a novel approach to learning Mahalanobis metric spaces using geometric approximation algorithms, which is a significant contribution to the field.\n2. The authors provide a provable guarantee on the number of violated constraints, which is a key advantage over existing methods.\n3. The experimental results demonstrate the effectiveness of the proposed algorithm on synthetic and real-world datasets.\n\nWeaknesses and concerns:\n\n1. Reviewer 3 raises concerns about the novelty of the contribution, suggesting that transforming the problem into a linear programming problem is not a complicated step. The authors should provide more motivation for their approach and highlight the key differences with existing methods.\n2. Reviewer 1 and 2 point out that the paper lacks a clear discussion of the state-of-the-art in the field and the novelty of the contribution. The authors should provide a more comprehensive overview of the existing literature and explain how their work builds upon or differs from previous research.\n3. Reviewer 2 raises concerns about the computational hardness of the problem, which is not fully addressed in the paper. The authors should provide more insight into the complexity of the problem and the implications for their algorithm.\n4. Reviewer 3 and 2 point out several minor errors and typos in the paper, which should be corrected in the final version.\n5. The authors' responses to the reviewer comments are generally satisfactory, but some points, such as the proof of Lemma 2.1, require further clarification.\n\nBased on these observations and concerns, I would recommend acceptance of the paper with minor revisions. The authors have made significant contributions to the field, and the paper has the potential to be a high-quality publication. However, the authors should address the concerns raised by the reviewers and provide more clarity on the novelty, state-of-the-art, and computational hardness of the problem.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "Mos9F9kDwkz",
      "source": "ICLR 2021",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I conclude that the paper should be accepted for publication.\n\nHere's my detailed reasoning:\n\nStrengths:\n\n1. **Originality**: The paper proposes a novel approach to complex query answering on incomplete knowledge graphs, which is a significant contribution to the field.\n2. **Effectiveness**: The proposed method achieves state-of-the-art results on standard multi-hop reasoning benchmarks, demonstrating its effectiveness.\n3. **Efficiency**: The method requires less training data and computational resources compared to existing methods, making it a more practical solution.\n4. **Explainability**: The paper provides a clear explanation of the intermediate solutions identified for each complex query atom, which is a valuable aspect of the method.\n\nWeaknesses:\n\n1. **Mathematical formalism**: Some reviewers found the mathematical formalism excessive, which may make the paper less accessible to non-experts.\n2. **Lack of ablation studies**: Reviewers suggested conducting ablation studies to investigate the impact of different neural link predictors and t-norms on the results.\n3. **Timing results**: The paper could benefit from more detailed timing results to compare the performance of the two optimization methods.\n\nAuthor responses:\n\nThe authors have addressed most of the concerns raised by the reviewers, providing additional experiments, clarifications, and explanations. They have also updated the paper to address the issues mentioned above.\n\nConclusion:\n\nWhile the paper has some weaknesses, its originality, effectiveness, efficiency, and explainability make it a valuable contribution to the field. The authors have demonstrated a willingness to address the concerns raised by the reviewers, and the updated paper addresses most of the issues. Therefore, I recommend accepting the paper for publication.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "Dmpi13JiqcX",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths of the paper:\n\n1. The paper proposes a novel approach to disentangling representations in pre-trained language models, which is a timely and important topic in NLP.\n2. The method is simple and easy to understand, and the authors provide a clear explanation of the approach.\n3. The experimental results are convincing and show that the proposed method outperforms previous approaches in certain tasks.\n4. The authors address several concerns raised by the reviewers, including the generalizability of the approach and the comparison to variational auto-encoders.\n\nWeaknesses of the paper:\n\n1. The paper does not provide a thorough comparison to state-of-the-art methods on standard benchmark datasets, which is a limitation.\n2. The authors do not provide a clear explanation of why they chose to mask only the last 9 layers of the model, and how this affects the results.\n3. The paper could benefit from more discussion on the interpretability of the learned masks and the implications of masking a small fraction of weights.\n4. Some of the reviewer comments and author responses suggest that the paper could be improved by including more experiments and analysis.\n\nBased on these strengths and weaknesses, I believe that the paper has the potential to be a valuable contribution to the field of NLP, but it requires further refinement and improvement.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "9_J4DrgC_db",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper proposes a novel exploration method, Deep Coherent Exploration, which unifies step-based and trajectory-based exploration for deep reinforcement learning algorithms on continuous control tasks.\n2. The method is mathematically solid, and the authors provide a detailed derivation of the recursive and analytical update for non-Markov policy gradients.\n3. The empirical results for on-policy methods (A2C and PPO) are strong, and the ablation experiments provide valuable insights.\n4. The authors have addressed most of the reviewer concerns, including the scalability of the method, the relationship to prior work, and the experimental results.\n\nWeaknesses:\n\n1. The paper's significance is limited by the fact that the proposed method does not obviously improve the performance of SAC, a state-of-the-art algorithm for continuous control tasks.\n2. The experiments are limited to a single domain (Mujoco) and a few tasks, which may not be representative of the broader applicability of the method.\n3. The integration of SAC with Deep Coherent Exploration is more heuristic than the integration with on-policy methods, and the authors have proposed a new mathematical formulation of Coherent-SAC, which may improve results.\n\nBased on these strengths and weaknesses, I conclude that the paper has made significant contributions to the field of reinforcement learning and has the potential to be a valuable addition to the conference proceedings.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "HyxWteSFwS",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper presents a novel approach to modeling time-evolving graphs using a temporal point process framework, which is a promising direction for future research.\n2. The authors propose a deep neural architecture that combines LSTM with time gates, stacked LSTM, and attention mechanisms to capture complex dependencies among interactions.\n3. The experimental results demonstrate the effectiveness of the proposed approach on multiple datasets, including a real-world financial application.\n4. The authors provide a detailed analysis of the model and its components, including the selection mechanism and fusion mechanism.\n\nWeaknesses:\n\n1. The main contributions of the paper are not particularly novel, as similar approaches have been proposed in previous works (e.g., Dai et al., 2017; Mei & Eisner, 2017; Trivedi, 2019).\n2. The experimental results are not entirely convincing, as the proposed method is the only deep model, and its maximum number of parameters can be up to 4x compared to the shallow models.\n3. The paper lacks a detailed analysis of the model's performance on commonly used benchmarks (e.g., DyRep, NeuralHawkes).\n4. The authors do not provide a clear justification for the use of coloring and hashing mechanism instead of simpler BFS/random walk routine to collect previous interactions.\n5. The paper has some minor issues with notation and presentation, which can be improved.\n\nAuthor responses:\n\nThe authors have addressed most of the reviewer comments, providing additional details and clarifications on the model's components and experimental results. However, some concerns remain:\n\n1. The authors' response to Reviewer 1's comment on the novelty of the contributions is not entirely convincing, as they mention that their approach is different from previous works, but do not provide a clear explanation of the differences.\n2. The authors' response to Reviewer 2's comment on the Log-likelihood function is incomplete, as they mention that the equation was a writing mistake, but do not provide a clear explanation of the correct equation.\n3. The authors' response to Reviewer 3's comment on the computational cost of the proposed network is not entirely clear, as they mention that the algorithm has a time complexity of o(m+n), but do not provide a clear explanation of how this affects the model's performance.\n\nFinal Decision: Accept\n\nWhile the paper has some weaknesses and minor issues, the authors have addressed most of the reviewer comments, and the proposed approach is a promising direction for future research. The experimental results demonstrate the effectiveness of the proposed approach, and the authors provide a detailed analysis of the model and its components. However, the paper would benefit from further clarification and justification of the main contributions, as well as a more detailed analysis of the model's performance on commonly used benchmarks."
    },
    {
      "paper_id": "5i4vRgoZauw",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I conclude that the paper should be accepted for publication.\n\nHere's my detailed reasoning:\n\nStrengths of the paper:\n\n1. The paper addresses an important problem in the field of computational neuroscience, which is to develop models of the primate visual system that are more biologically plausible.\n2. The authors propose three complementary strategies to reduce the number of supervised synaptic updates required to produce an adult-like ventral visual stream, which is a significant contribution to the field.\n3. The paper presents a thorough and well-structured analysis of the results, including a clear explanation of the methods and a detailed discussion of the implications of the findings.\n4. The authors have addressed most of the concerns raised by the reviewers, including the limitations of the Brain-Score metric and the analogy between artificial neural networks and the development of the primate visual system.\n\nWeaknesses of the paper:\n\n1. Some reviewers have raised concerns about the interpretation of the results, particularly with regards to the Brain-Score metric and the analogy between artificial neural networks and the development of the primate visual system.\n2. The paper could benefit from more discussion of the theoretical foundations of the proposed methods and the implications of the findings for our understanding of the primate visual system.\n3. Some reviewers have suggested that the paper could be improved by including more details about the methodological choices and the results of the experiments.\n\nAuthor responses:\n\nThe authors have addressed most of the concerns raised by the reviewers, including the limitations of the Brain-Score metric and the analogy between artificial neural networks and the development of the primate visual system. They have also provided additional details about the methodological choices and the results of the experiments.\n\nConclusion:\n\nBased on the strengths and weaknesses of the paper, as well as the author responses, I conclude that the paper should be accepted for publication. The paper presents a significant contribution to the field of computational neuroscience, and the authors have addressed most of the concerns raised by the reviewers. However, the paper could benefit from more discussion of the theoretical foundations of the proposed methods and the implications of the findings for our understanding of the primate visual system.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "Bkel6ertwS",
      "source": "ICLR 2020",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\n**Strengths:**\n\n1. The paper presents an interesting application of machine learning to predict DNA folding patterns using Recurrent Neural Networks (RNNs).\n2. The authors demonstrate the effectiveness of their approach using a bidirectional LSTM RNN model, which outperforms other models in terms of predictive accuracy.\n3. The paper explores the use of epigenetic features, such as ChIP-Seq data, to improve the prediction of chromatin folding patterns.\n\n**Weaknesses and concerns:**\n\n1. **Lack of novelty:** Reviewer 3 raises concerns about the paper's similarity to previously published works, which are not adequately cited. The authors' response acknowledges this issue but does not provide a clear explanation for why their work is distinct.\n2. **Methodological limitations:** Reviewer 1 and 3 point out that the paper lacks a clear explanation of the data and methods used. The authors' response provides some clarification, but the paper still requires more detail on data preprocessing, feature representation, and model hyperparameters.\n3. **Evaluation metrics:** Reviewer 1 and 3 suggest that the paper's evaluation metrics are limited and do not provide a comprehensive picture of the models' performance. The authors' response adds some additional metrics, but the paper still requires more thorough evaluation.\n4. **Generalizability:** Reviewer 1 raises concerns about the paper's generalizability to other Hi-C datasets and epigenetic features. The authors' response acknowledges this limitation but does not provide a clear explanation for why their approach is not generalizable.\n5. **Lack of discussion:** Reviewer 2 points out that the paper lacks a discussion on the advantages and disadvantages of using regression versus neural networks for this application. The authors' response provides some additional discussion, but the paper still requires more in-depth analysis.\n\n**Author responses:**\n\nThe authors have provided detailed responses to the reviewers' comments, addressing many of the concerns raised. However, some issues remain unresolved, such as the lack of novelty and methodological limitations.\n\n**Conclusion:**\n\nWhile the paper presents an interesting application of machine learning to predict DNA folding patterns, it has several limitations that need to be addressed. The lack of novelty, methodological limitations, and limited evaluation metrics are significant concerns that need to be resolved. The authors' responses have provided some clarification, but the paper still requires more detail and thorough evaluation.\n\n**Final Decision:** Reject\n\nThe paper has potential, but it requires significant revisions to address the concerns raised by the reviewers. The authors need to provide more detail on the data and methods used, evaluate their approach more comprehensively, and address the limitations of their work. With revisions, the paper may be considered for publication in a top-tier conference."
    },
    {
      "paper_id": "DigrnXQNMTe",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel framework for generalizing probability kernels on discrete distributions, which is an interesting and timely topic.\n2. The authors provide a clear and concise abstract, and the paper is well-organized.\n3. The authors have addressed some of the reviewer comments, such as clarifying the notation and providing more details on the theoretical results.\n\n**Weaknesses:**\n\n1. The paper has several major issues, including:\n\t* Incomplete proofs (e.g., Theorem 5 is missing, and the proof of Theorem 7 is incorrect).\n\t* Lack of experimental evaluation (Reviewer 2 and Reviewer 3 mention that there is no experimental evaluation).\n\t* Inconsistent notation (Reviewer 3 and Reviewer 4 mention that the notation is confusing).\n\t* Lack of clear motivation for the discrete setting (Reviewer 3 mentions that the setting is unusual and requires more motivation).\n2. The paper has several minor issues, including:\n\t* Typos and grammatical errors (Reviewer 3 and Reviewer 4 mention that the paper has numerous typos and imprecisions).\n\t* Lack of clear explanation of some concepts (e.g., the Stein operator in a discrete setting, as mentioned by Reviewer 3).\n\n**Author responses:**\n\nThe authors have addressed some of the reviewer comments, but not all of them. They have clarified the notation, provided more details on the theoretical results, and addressed some of the minor issues. However, they have not provided a complete proof of Theorem 5, and they have removed the discussion of KSD due to an incorrect proof.\n\n**Conclusion:**\n\nBased on the analysis above, I believe that the paper has significant weaknesses that need to be addressed before it can be considered for publication in a top-tier conference. While the authors have made some progress in addressing the reviewer comments, the paper still lacks a complete and rigorous treatment of the theoretical results, experimental evaluation, and clear motivation for the discrete setting.\n\n**Final Decision:**\n\nReject\n\nThe paper has significant weaknesses that need to be addressed before it can be considered for publication in a top-tier conference. While the authors have made some progress in addressing the reviewer comments, the paper still lacks a complete and rigorous treatment of the theoretical results, experimental evaluation, and clear motivation for the discrete setting."
    },
    {
      "paper_id": "t86MwoUCCNe",
      "source": "ICLR 2021",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I conclude that the paper has made significant contributions to the field of distributed mean estimation and variance reduction. The authors have proposed a novel approach using lattice theory to achieve optimal bounds without relying on input norm, which is a significant improvement over previous work.\n\nThe paper has several strengths:\n\n1. **Novel approach**: The authors have introduced a new connection between lattice theory and distributed mean estimation, which is a significant contribution to the field.\n2. **Optimal bounds**: The authors have shown that their approach achieves optimal bounds without relying on input norm, which is a significant improvement over previous work.\n3. **Experimental evaluation**: The authors have provided experimental results that demonstrate the effectiveness of their approach.\n4. **Clear writing**: The authors have written a clear and concise paper that is easy to follow.\n\nHowever, the paper also has some weaknesses:\n\n1. **Limited experimental evaluation**: While the authors have provided experimental results, they are limited to a small number of machines (n=2) and a single dataset.\n2. **Lack of comparison to other approaches**: The authors have not compared their approach to other existing approaches, which makes it difficult to evaluate the significance of their contribution.\n3. **Some minor errors**: The authors have made some minor errors in the paper, which need to be corrected.\n\nBased on the reviewer comments and author responses, I believe that the authors have addressed most of the concerns raised by the reviewers. The authors have provided clear explanations for the changes they will make in the revision, and I believe that the paper will be significantly improved as a result.\n\nTherefore, I recommend that the paper be accepted for publication.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "0p-aRvcVs-U",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper proposes a novel method for multitask learning, called $\\alpha$VIL, which adjusts task weights dynamically during training by making direct use of task-specific updates of the underlying model's parameters between training epochs.\n2. The paper is well-written and easy to follow, with a clear summary of related work and a well-motivated methodology.\n3. The authors provide empirical studies on tasks of computer vision and natural language understanding, which demonstrate the effectiveness of their method.\n\nWeaknesses:\n\n1. Reviewer 1 and Reviewer 3 express concerns about the lack of theoretical justification or formal analysis of the proposed methodology. While the authors acknowledge this limitation, they do not provide a clear plan for addressing it in the camera-ready version.\n2. Reviewer 2 and Reviewer 3 are not convinced by the novelty of the proposed method, as it seems similar to existing methods such as dynamic task weighting and meta-learning algorithms like MAML or Reptile.\n3. The experimental results are not convincing enough to justify the proposed method, as the improvements over the baselines are marginal and sometimes lower. Reviewer 3 suggests that the results fall within the statistically insignificant range.\n4. The authors' response to Reviewer 3's question about the difference between $\\alpha$VIL and task-specific weights is not entirely clear, and the authors do not provide a clear explanation for why they chose to use separate $\\alpha$ parameters.\n\nCommon criticisms:\n\n1. Lack of theoretical motivation/justification of the proposed algorithm.\n2. Marginal improvements over the baselines in the experimental results.\n3. Need for more experiments and/or ablation studies to show the efficacy of the method.\n\nAuthor responses:\n\n1. The authors acknowledge the limitations of their work and plan to address them in the camera-ready version.\n2. They provide additional explanations for their method and respond to specific questions from the reviewers.\n3. They point out that the improvements yielded by multitask learning on NLU tasks are often small and that their method outperforms the compared methods on the MultiMNIST task.\n\nBased on the detailed reasoning above, I conclude that the paper has some strengths, but also significant weaknesses that need to be addressed. While the authors have made efforts to respond to the reviewers' comments, the paper still lacks a clear theoretical justification and the experimental results are not convincing enough to justify the proposed method.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "hE3JWimujG",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper presents a novel and intriguing hypothesis that the cerebellum can be seen as a decoupled neural interface (DNI) that helps the cerebral cortex solve the locking problem in credit assignment.\n2. The authors propose a specific model, cortico-cerebellar-DNI (CC-DNI), that combines the cerebellum with DNI to facilitate learning in neural circuits.\n3. The paper presents a range of experiments that demonstrate the effectiveness of the CC-DNI model in various tasks, including sensorimotor and cognitive tasks.\n4. The authors have addressed the reviewer comments and substantially revised the manuscript to improve clarity and add specific predictions and insights.\n\nWeaknesses:\n\n1. Some reviewers have raised concerns that the paper does not offer new insights into either the cerebellum or DNI, but rather juxtaposes existing knowledge.\n2. The paper focuses primarily on the temporal feedback problem, and it is not clear whether the results generalize to other domains.\n3. The authors have not provided a clear comparison with experimental findings from cerebellum, and the link between the model and biological cerebellum appears somewhat weak.\n4. Some minor errors in citations and figure labels have been pointed out by the reviewers.\n\nAuthor responses:\n\nThe authors have addressed the reviewer comments and substantially revised the manuscript to improve clarity and add specific predictions and insights. They have added three new figures, a new section, and extended the discussion to highlight predictions made by the model. The authors have also clarified the use of bootstrapping in their model and suggested that the numerous modules known to exist in the cerebellum may act as an efficient bootstrapping mechanism.\n\nConclusion:\n\nBased on the strengths and weaknesses of the paper, as well as the author responses, I believe that the paper has been substantially improved after addressing the reviewer comments. The authors have provided a clear and well-written manuscript that presents a novel and intriguing hypothesis, proposes a specific model, and demonstrates its effectiveness in various tasks. While some concerns remain, the authors have addressed them and provided additional insights and predictions.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "Qpik5XBv_1-",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel approach to integrating language and visual processing, which is a timely and important problem in computer vision and AI research.\n2. The authors provide a clear and well-structured presentation of their method and experiments.\n3. The paper demonstrates significant improvements over state-of-the-art models on several datasets, which is a strong empirical result.\n\n**Weaknesses:**\n\n1. The paper lacks a clear conceptual motivation for the proposed approach. While the authors cite some cognitive science studies, they do not provide a detailed explanation of how language affects low-level visual processing.\n2. The ablation studies are limited, and the authors do not provide a satisfactory analysis of the actual cause of the model's success. The interaction between language and visual input is not well understood, and the authors' response to this criticism is not convincing.\n3. The empirical results are not entirely convincing, as the full model struggles to match existing works on certain metrics, and the results on the validation set are not as good as on the test set, which may indicate over-tuning.\n4. The paper lacks statistical significance tests, which makes it difficult to evaluate the robustness of the results.\n\n**Reviewer comments and author responses:**\n\n1. Reviewer 1 raises several concerns about the novelty and contribution of the paper, which the authors address in their response. However, the reviewer's concerns about the lack of exploration of other modeling approaches are still valid.\n2. Reviewer 2 raises concerns about the empirical results, which the authors address in their response. However, the reviewer's concerns about the over-tuning of the model are still valid.\n3. Reviewer 3 provides a positive review, but their comments are not as detailed as those of the other reviewers.\n4. Reviewer 4 raises several concerns about the significance and quality of the paper, which the authors address in their response. However, the reviewer's concerns about the lack of conceptual motivation and error analysis are still valid.\n\n**Final decision:**\n\nBased on the strengths and weaknesses of the paper, as well as the reviewer comments and author responses, I conclude that the paper should be **Rejected** for publication at a top-tier conference. While the paper proposes a novel approach to integrating language and visual processing, it lacks a clear conceptual motivation, and the ablation studies and empirical results are not entirely convincing. The paper also lacks statistical significance tests, which makes it difficult to evaluate the robustness of the results. To improve the paper, the authors should address these concerns and provide a more detailed explanation of the conceptual motivation, a more thorough analysis of the interaction between language and visual input, and statistical significance tests to evaluate the robustness of the results."
    },
    {
      "paper_id": "0p-aRvcVs-U",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper proposes a novel approach to multitask learning, which is a timely and relevant topic in the field of machine learning.\n2. The authors provide a clear and concise explanation of their method, making it easy to follow and understand.\n3. The empirical evaluation is performed on a variety of tasks, including computer vision and natural language understanding, which demonstrates the versatility of the proposed method.\n4. The authors respond thoughtfully to the reviewer comments, addressing the concerns and providing additional insights.\n\nWeaknesses:\n\n1. The reviewer comments highlight several concerns, including the lack of theoretical justification, limited experimental results, and similarity to existing methods.\n2. The experimental results show that the proposed method does not consistently outperform the baselines, and the improvements are often marginal.\n3. The authors acknowledge the limitations of their method, including the lack of theoretical motivation and the need for additional experiments and ablation studies.\n\nBased on the reviewer comments and author responses, I agree that the paper has several areas for improvement. However, I also believe that the paper has some strengths, such as the novel approach and clear explanation.\n\nTo address the concerns, I would recommend that the authors:\n\n1. Provide a more thorough theoretical justification for their method, including a formal analysis of the proposed methodology.\n2. Conduct additional experiments and ablation studies to demonstrate the efficacy of their method.\n3. Address the similarity to existing methods and provide a clear explanation of how their method differs.\n\nConsidering these recommendations, I would conclude that the paper is not yet ready for publication in its current form. However, with some revisions and additional work, it has the potential to be a strong contribution to the field.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "UOOmHiXetC",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper presents a novel method, Shoot Tree Search (STS), which modifies the expansion phase of Monte-Carlo Tree Search (MCTS) to control the trade-off between depth and breadth of the search.\n2. The authors provide a thorough empirical evaluation of STS on challenging domains, such as Sokoban and Google Research Football (GRF), and demonstrate its effectiveness in achieving higher scores compared to MCTS and other baseline methods.\n3. The paper discusses the bias-variance trade-off and how STS can be viewed as a mechanism controlling depth and breadth of the search, which is an interesting aspect of the work.\n\n**Weaknesses:**\n\n1. The paper lacks technical novelty, as multi-step expansion has already been used in existing works (e.g., [1] by Soemers et al., 2016). The authors need to provide a more detailed discussion on how their method differs from existing works and why it is novel.\n2. The reviewer comments highlight several issues with the paper, including unclear or questionable parts, missing related work, and a lack of intuitive explanation of why STS is better than MCTS.\n3. The author responses address some of the reviewer comments, but some concerns remain, such as the lack of discussion on the bias-variance trade-off and the importance of using neural networks for leaf evaluation.\n\n**Author responses:**\n\nThe author responses address some of the reviewer comments, but some concerns remain. The authors provide new experimental results, which strengthen the evidence that the advantage of STS stems from the algorithmic reasons by building a more efficient search tree. However, some reviewer comments, such as the lack of discussion on the bias-variance trade-off and the importance of using neural networks for leaf evaluation, are not fully addressed.\n\n**Conclusion:**\n\nBased on the detailed analysis, I conclude that the paper has some strengths, but also several weaknesses that need to be addressed. While the paper presents a novel method and demonstrates its effectiveness, the lack of technical novelty and unclear or questionable parts in the paper are significant concerns. The author responses address some of the reviewer comments, but some concerns remain.\n\n**Final Decision:**\n\nAccept, but with major revisions.\n\nThe paper has potential, but it requires significant revisions to address the concerns raised by the reviewers. The authors need to provide a more detailed discussion on the technical novelty of their method, clarify unclear or questionable parts, and address the concerns raised by the reviewers. With major revisions, the paper can be improved to meet the standards of a top-tier conference."
    },
    {
      "paper_id": "0p-aRvcVs-U",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel approach to multitask learning, which is a timely and relevant topic in the field of machine learning.\n2. The authors provide a clear and concise explanation of their method, making it easy to follow and understand.\n3. The empirical evaluation is performed on a variety of tasks, including computer vision and natural language understanding, which demonstrates the versatility of the proposed method.\n4. The authors respond thoughtfully to the reviewer comments, addressing the concerns and providing additional insights.\n\n**Weaknesses:**\n\n1. The reviewer comments highlight several concerns, including the lack of theoretical justification, limited experimental results, and similarity to existing methods.\n2. The experimental results are not convincing, with the proposed method not consistently outperforming the baselines in most cases.\n3. The authors acknowledge the limitations of their method, including the lack of theoretical motivation and the need for additional experiments and ablation studies.\n\n**Reviewer comments:**\n\n1. Reviewer 1 raises concerns about the lack of theoretical justification and the limited experimental results.\n2. Reviewer 2 criticizes the proposed method as being ad hoc and lacking clear justification, and questions the novelty of the approach.\n3. Reviewer 3 is not convinced by the proposed method, citing concerns about the lack of clear explanation, limited experimental results, and similarity to existing methods.\n\n**Author responses:**\n\n1. The authors respond thoughtfully to the reviewer comments, addressing the concerns and providing additional insights.\n2. They acknowledge the limitations of their method and plan to address them in future work.\n\n**Conclusion:**\n\nWhile the paper has some strengths, including a novel approach and clear explanation, the reviewer comments and author responses highlight several concerns that need to be addressed. The experimental results are not convincing, and the proposed method is not consistently outperforming the baselines. The authors acknowledge the limitations of their method and plan to address them in future work.\n\n**Final Decision:**\n\nReject\n\nThe paper has some potential, but it requires significant revisions to address the concerns raised by the reviewers. The authors need to provide a more thorough theoretical justification, conduct additional experiments and ablation studies, and clarify the novelty of their approach. With these revisions, the paper may be considered for publication in a top-tier conference."
    },
    {
      "paper_id": "mxfRhLgLg_",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author response (if available), I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper tackles an important and practical problem of ecological inference, which is applicable to various settings, including voting behavior.\n2. The proposed approach is an interesting direction to approximate the loss function of the ecological inference problem in an efficient manner, enabling different extensions, especially using Bayesian neural networks.\n3. The paper evaluates the proposed model using real Maryland 2018 midterm election data and produces interesting insights.\n\n**Weaknesses:**\n\n1. The paper is not easy to follow due to various typos, minor writing problems, and unclear structure. Reviewer 1 and Reviewer 4 pointed out several issues with the paper's clarity and organization.\n2. The experiments are incomplete, unclear, and unconvincing of the significance of the proposed models. Reviewer 2 highlighted the lack of comparison to a standard MLM as a baseline and the need for more analysis to understand the results.\n3. The paper lacks details on how the proposed methods and baselines are implemented, making it difficult to reproduce the results. Reviewer 2 and Reviewer 4 pointed out the need for more experimental details.\n4. The related work is not adequately cited, and the authors fail to discuss the relationships between their approach and other methods in the machine learning community. Reviewer 4 emphasized the importance of discussing the connections to other problems, such as distribution regression, multiple-instance learning, and collective graphical models.\n\n**Author Response:**\n\nUnfortunately, there is no author response available to address the concerns raised by the reviewers.\n\n**Final Decision:**\n\nBased on the strengths and weaknesses, I recommend **Rejecting** the paper for publication at this time. While the paper tackles an important problem and proposes an interesting approach, the issues with clarity, completeness, and reproducibility of the experiments are significant concerns that need to be addressed. The authors should revise the paper to address the reviewers' comments, provide more experimental details, and discuss the relationships between their approach and other methods in the machine learning community."
    },
    {
      "paper_id": "25OSRH9H0Gi",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper attempts to bridge the gap between theory and practice in meta-learning, which is a valuable contribution.\n2. The authors provide a clear and well-organized review of recent advances in meta-learning theory and its application to few-shot classification.\n3. The experimental results show that the proposed regularization terms improve the performance of popular meta-learning algorithms.\n\nWeaknesses:\n\n1. The proposed regularization terms are not novel and are similar to existing techniques such as weight decay and spectral normalization.\n2. The experimental results, while promising, are not statistically significant in all cases, and the improvement is not substantial.\n3. The paper lacks a clear comparison with recent and more complicated few-shot learning methods.\n4. The theoretical assumptions are based on the optimal predictors, which may not be realistic in practice.\n5. The paper does not provide a clear explanation of how the proposed regularization terms can be applied to more complicated models.\n\nReviewer comments and author responses:\n\n1. Reviewer 1 raises concerns about the novelty of the proposed regularization terms and the lack of significant improvement in the experimental results.\n2. Reviewer 2 points out that the theoretical setting is not fully consistent with the few-shot learning setting and suggests that the authors should make more discussions on this.\n3. Reviewer 3 raises concerns about the efficacy of the proposed methods, the introduction of hyperparameters, and the terminology used.\n4. Reviewer 4 is skeptical about the novelty of the second regularization term and suggests that the authors should add more comparisons with recent methods.\n\nAuthor responses:\n\n1. The authors address the concerns raised by the reviewers, providing additional explanations and experimental results.\n2. They clarify that their goal is not to propose a novel regularization that outperforms the state of the art but rather to study whether current theoretical results agree with the real-world behavior of popular meta-learning algorithms.\n\nConclusion:\n\nWhile the paper has some strengths, the weaknesses and concerns raised by the reviewers are significant. The proposed regularization terms are not novel, and the experimental results, although promising, are not statistically significant in all cases. The paper lacks a clear comparison with recent and more complicated few-shot learning methods, and the theoretical assumptions are based on the optimal predictors, which may not be realistic in practice.\n\nConsidering these factors, I recommend rejecting the paper for publication in a top-tier conference. However, I suggest that the authors revise the paper to address the concerns raised by the reviewers and provide a more comprehensive comparison with recent and more complicated few-shot learning methods.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "qiAxL3Xqx1o",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses (or lack thereof), I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel approach to graph generation using a geometric graph generative adversarial network (GG-GAN), which addresses several challenges in graph generation.\n2. The authors provide a clear and well-organized presentation of their method, including theoretical support and experimental results.\n3. The paper has some interesting properties, such as isomorphism consistency, expressive power, scalability, and novelty.\n\n**Weaknesses:**\n\n1. Reviewer 1 and Reviewer 4 raise concerns about the limited experimental results, specifically the small size of the datasets and the lack of comparison with other state-of-the-art methods.\n2. Reviewer 2 and Reviewer 4 point out that the paper may over-claim its contributions, as some of the properties mentioned (e.g., novelty, scalability) are not entirely new or unique to GG-GAN.\n3. Reviewer 2 and Reviewer 5 raise concerns about the theoretical analysis, specifically the connection between the theorems and the proposed GG-GAN.\n4. Reviewer 5 points out that the introduction of $\\phi$ is confusing and its implications are not well justified.\n5. Reviewer 4 raises concerns about the literature review, specifically the lack of a comprehensive discussion of the connection between this paper and previous work.\n\n**Author Response:**\n\nUnfortunately, there is no author response available, which makes it difficult to address the concerns raised by the reviewers.\n\n**Final Decision:**\n\nBased on the strengths and weaknesses of the paper, as well as the concerns raised by the reviewers, I recommend **Reject**. While the paper proposes an interesting approach to graph generation, the limited experimental results, potential over-claiming of contributions, and concerns about the theoretical analysis and literature review are significant enough to warrant rejection. The authors should be encouraged to address these concerns and provide a revised version of the paper that better addresses the reviewers' comments."
    },
    {
      "paper_id": "rvosiWfMoMR",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper proposes a novel approach to automatic music accompaniment using generative adversarial networks (GANs) and CycleGAN, which is a well-established framework for unpaired image-to-image translation.\n2. The authors provide a clear and concise introduction to the problem, related works, and their proposed method.\n3. The paper presents promising results on the task of generating drum accompaniment given a bass line, and the authors provide a detailed evaluation of their method using human listener testing and automatic offline scoring.\n4. The authors have addressed most of the reviewer comments and provided additional details to clarify their method and results.\n\nWeaknesses:\n\n1. The paper has some limitations, such as the narrow scope of the experiments (only bass, drums, and vocals) and the lack of comparison with other state-of-the-art methods.\n2. The authors have not provided enough details about the source separation model (Demucs) used in their experiments, which is a critical component of their method.\n3. The paper has some minor errors and inconsistencies, such as the incorrect citation of the Mel scale and the lack of clarity in the description of the experimental settings.\n4. The authors have not provided enough information about the cultural background and genre of the music experts used in their evaluation.\n\nBased on these strengths and weaknesses, I believe that the paper has the potential to be published in a top-tier conference, but it requires some additional work to address the limitations and minor errors.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "BIIwfP55pp",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel approach to combining meta-reinforcement learning (meta-RL) and imitation learning (IL), which is a promising direction for improving sample efficiency in learning new tasks.\n2. The experimental results are generally encouraging, with PERIL substantially outperforming the baselines on a range of 2D and 3D tasks.\n3. The paper provides a clear and concise introduction to the problem and the proposed approach.\n\n**Weaknesses:**\n\n1. The paper relies on a strong assumption that an expert distribution over trajectories conditioned on the learned latent z is available, which seems to be a fairly restrictive assumption.\n2. The clarity of the paper is compromised by several issues, including:\n\t* Confusing notation and terminology (e.g., \"primal inference,\" \"privileged information\").\n\t* Unclear explanations of key concepts (e.g., the task-dependent objective G(Ï„)).\n\t* Undefined loss functions (e.g., â„’mi, â„’D_KL).\n3. The related work section is incomplete, with several key areas requiring citations (e.g., meta-IL, posterior sampling with meta-RL).\n4. The experiments are limited, with only a few tasks evaluated, and the behavior cloning baseline with noisy demonstrations is not a fair comparison.\n\n**Reviewer comments:**\n\n1. Reviewer 1 raises several concerns about the complexity of the method, the necessity of all the components, and the notation and mathematical formulation.\n2. Reviewer 2 points out several issues with the related work section, including the lack of citation for similar context-conditional meta-learning methods.\n3. Reviewer 3 raises concerns about the clarity of the paper, the treatment of prior work, and the experiments.\n4. Reviewer 4 recommends rejection due to the strong assumption, clarity issues, and lack of related work citations.\n\n**Author responses:**\n\n1. The authors address some of the reviewer comments, but not all of them.\n2. They provide additional explanations and clarifications, but some of the issues remain unclear.\n\n**Conclusion:**\n\nBased on the detailed analysis, I conclude that the paper has several strengths, but also significant weaknesses. While the proposed approach is promising, the paper's clarity and related work sections are compromised by several issues. The strong assumption and limited experiments also raise concerns. Considering the reviewer comments and author responses, I recommend **REJECTION** for publication in a top-tier conference.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "HNA0kUAFdbv",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper proposes a novel approach to learning layout representation using a large-scale pre-training technique, which is a significant contribution to the field.\n2. The authors have constructed a large-scale dataset of over 1 million slides, which is a valuable resource for the community.\n3. The paper demonstrates the effectiveness of the proposed approach on several downstream tasks, including element role labeling and image captioning.\n4. The authors have addressed some of the concerns raised by the reviewers, such as providing more details on the dataset construction and evaluation methods.\n\nWeaknesses:\n\n1. The evaluation of the proposed approach is limited to a few tasks, and the authors have not compared their method with other state-of-the-art approaches in the field.\n2. The paper lacks a thorough evaluation of the proposed approach on more complex tasks, such as layout auto-completion and layout retrieval.\n3. The authors have not provided enough details on the dataset statistics, such as the number of elements in each slide, templates, and completeness of properties.\n4. The paper has some minor errors in formatting and referencing, which need to be corrected.\n\nBased on the strengths and weaknesses, I believe that the paper has the potential to be published in a top-tier conference, but it requires some revisions to address the concerns raised by the reviewers.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "OGg9XnKxFAH",
      "source": "ICLR 2021",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel approach to improve uncertainty estimation and robustness using a multi-input multi-output (MIMO) configuration, which is a significant contribution to the field.\n2. The experimental results demonstrate a significant improvement in negative log-likelihood, accuracy, and calibration error on various datasets, including CIFAR10, CIFAR100, ImageNet, and their out-of-distribution variants.\n3. The authors provide a thorough evaluation of the method, including a detailed analysis of the loss landscape, parameter/activation projection, and conditional variance of the activations within the network.\n\n**Weaknesses:**\n\n1. The paper has some minor formatting issues, such as inconsistent notation and font usage.\n2. Some reviewers have raised concerns about the originality of the method, as it bears similarities to other multi-input multi-output approaches.\n3. The authors have not provided a detailed theoretical analysis of the emergence of independence between subnetworks, which is an important aspect of the method.\n4. Some reviewers have questioned the computational costs of the method, particularly in terms of inference delay and FLOPS.\n\n**Author Responses:**\n\nThe authors have addressed most of the concerns raised by the reviewers, including:\n\n1. Clarifying the source of independence between subnetworks and providing empirical evidence to support this claim.\n2. Addressing the originality of the method and highlighting its differences from other multi-input multi-output approaches.\n3. Providing a detailed analysis of the computational costs of the method, including inference delay and FLOPS.\n4. Clarifying the notation and formatting issues.\n\n**Conclusion:**\n\nBased on the strengths and weaknesses of the paper, as well as the author responses, I believe that the paper has made significant contributions to the field and has addressed most of the concerns raised by the reviewers. The experimental results are thorough and demonstrate a significant improvement in uncertainty estimation and robustness. While there are some minor formatting issues and concerns about originality, the authors have addressed these concerns in their responses.\n\n**Final Decision:** Accept"
    },
    {
      "paper_id": "98ntbCuqf4i",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully reviewing the paper, the reviewer comments, and the author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper proposes a novel exploration strategy, Max-Q Entropy Search (MQES), which is a generally information-theoretic exploration principle for continuous reinforcement learning (RL) algorithms.\n2. MQES formulates the exploration policy to maximize the information about the globally optimal distribution of the Q-function, which can explore optimistically and avoid over-exploration by recognizing epistemic and aleatoric uncertainty.\n3. The authors provide a practical implementation of MQES, incorporating distributional and ensemble Q-function approximations to make it tractable.\n4. Empirical evaluations show that MQES outperforms state-of-the-art algorithms on Mujoco environments.\n\nWeaknesses:\n\n1. The paper has some clarity issues, with some concepts and notations being unclear or inaccurate. The authors have addressed some of these issues in their response, but more work is needed to ensure that the paper is easy to follow.\n2. The paper lacks ablation studies to demonstrate the effectiveness of MQES. The authors have added some ablation studies in their response, but more work is needed to fully understand the impact of MQES.\n3. The paper has some minor issues, such as typos and notation inconsistencies, which need to be addressed.\n4. The paper could benefit from more discussion on the impact of hyperparameters on the performance of MQES.\n\nBased on these strengths and weaknesses, I conclude that the paper has potential but needs further refinement before publication. The authors have addressed some of the reviewer comments, but more work is needed to ensure that the paper is clear, concise, and well-written.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "6zaTwpNSsQ2",
      "source": "ICLR 2021",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\n**Strengths:**\n\n1. The paper introduces a new representation, Block Minifloat (BM), which combines the benefits of floating-point and fixed-point representations.\n2. The authors provide a thorough exploration of the design space, including various block sizes, exponent biases, and mantissa widths.\n3. The paper presents impressive results, including a 4.1x reduction in area and 2.3x reduction in energy consumption compared to FP8.\n4. The authors provide a detailed hardware evaluation, including synthesis results and power estimates.\n\n**Weaknesses:**\n\n1. The paper's novelty is somewhat limited, as the shared-exponent bias concept is not new, and the authors do not provide a clear explanation of why \"exponents up to 4 bits offer distinct advantages\" for Kulishch accumulation.\n2. The paper's results are not entirely clear, with some tables and figures being confusing or difficult to interpret.\n3. The authors do not provide a thorough explanation of the hardware overhead for supporting denormal numbers.\n4. The paper's scope is somewhat narrow, focusing primarily on ResNet-18 and ImageNet, with limited exploration of larger networks.\n\n**Reviewer comments and author responses:**\n\n1. Reviewer 1 raises several concerns, including the lack of novelty in the shared-exponent bias concept and the need for more information on the accumulator and its advantages.\n2. Reviewer 2 provides a more positive assessment, highlighting the paper's contributions in hardware implementation and area/power estimates.\n3. Reviewer 3 raises several concerns, including the need for more explanation of the minifloat distribution alignment and the Kulishch accumulator.\n\n**Author responses:**\n\n1. The authors provide additional information and clarification on several points, including the alignment of minifloat distribution and value distribution, the Kulishch accumulator, and the hardware overhead for supporting denormal numbers.\n2. The authors address several of the reviewer's concerns, including the need for more explanation of the hardware overhead and the potential for overhead in supporting multiple formats.\n\n**Conclusion:**\n\nWhile the paper has several strengths, including a thorough exploration of the design space and impressive results, it also has several weaknesses, including limited novelty and unclear results. The author responses address several of the reviewer's concerns, but some issues remain, such as the need for more explanation of the hardware overhead and the potential for overhead in supporting multiple formats.\n\n**Final Decision:**\n\nAccept\n\nThe paper's contributions, including the introduction of a new representation and impressive results, outweigh its limitations. The author responses address several of the reviewer's concerns, and the paper has the potential to make a significant impact in the field of deep learning and hardware design. However, the authors should be encouraged to address the remaining concerns and provide more clarity in their future revisions."
    },
    {
      "paper_id": "9GUTgHZgKCH",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel algorithm for pruning deep neural networks, which is a significant contribution to the field.\n2. The authors provide a theoretical foundation for their algorithm, which is based on the recent theory of implicit and explicit regularization in deep ReLU networks.\n3. The paper presents some experimental results that demonstrate the efficiency of the algorithm in reducing the number of neurons with provably almost no change in the learned function.\n\n**Weaknesses:**\n\n1. The paper is not well-written, and the presentation needs considerable improvement. The authors use footnotes to explain important concepts, but many definitions are missing, and the material in the footnotes can be included in the main text with a more natural flow.\n2. The experiments are not convincing, and the authors need to conduct more experiments on more complex datasets and compare their method to state-of-the-art pruning techniques.\n3. The paper lacks motivation for the proposed technique, and the authors need to provide more details about the theory behind pruning and reducing overfitting.\n4. The authors refer to unpublished work, which makes it difficult for reviewers to evaluate the correctness of the paper.\n5. The paper contains typos and grammatical errors, which need to be corrected.\n\n**Author responses:**\n\nThe authors have provided detailed responses to the reviewer comments, addressing many of the concerns raised. They have clarified their notation, corrected typos, and provided more explanations about their algorithm and theory. However, some concerns remain, such as the need for more experiments, better presentation, and clearer motivation for the proposed technique.\n\n**Conclusion:**\n\nBased on the strengths and weaknesses of the paper, as well as the author responses, I conclude that the paper is not yet ready for publication in a top-tier conference. While the authors have made significant contributions to the field, the paper needs further improvement in terms of presentation, experimentation, and motivation. The authors need to address the concerns raised by the reviewers and provide more convincing evidence of the efficiency and effectiveness of their algorithm.\n\n**Final Decision: Reject**\n\nThe paper has potential, but it requires significant revisions to address the concerns raised by the reviewers. The authors need to improve the presentation, conduct more experiments, and provide clearer motivation for the proposed technique. Once these revisions are made, the paper can be considered for publication in a top-tier conference."
    },
    {
      "paper_id": "w6Vm1Vob0-X",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel GNN architecture that addresses the limitation of existing GNNs on disassortative graphs.\n2. The authors provide a clear and concise explanation of their method, making it accessible to a wide range of researchers.\n3. The experimental results demonstrate the effectiveness of the proposed method on various benchmark datasets.\n4. The authors address the concerns raised by the reviewers and provide additional technical details and experimental results.\n\n**Weaknesses:**\n\n1. The paper lacks theoretical results, which is a significant concern for a top-tier conference.\n2. The complexity of the proposed method is still a concern, as the authors' claim of O(p Ã— |E|) complexity is disputed by Reviewer 1 and 4.\n3. The experimental results are limited to node classification tasks, and the authors are encouraged to explore other evaluation tasks.\n4. The paper relies heavily on the use of Chebyshev polynomials, which may not be the most efficient approach.\n\n**Author responses:**\n\nThe authors provide detailed responses to the reviewers' concerns, addressing the complexity issue, novelty, and experimental results. However, some concerns remain, such as the complexity of the proposed method and the limited experimental results.\n\n**Conclusion:**\n\nWhile the paper has several strengths, including a novel GNN architecture and effective experimental results, the lack of theoretical results and concerns about complexity and experimental scope are significant drawbacks. After careful consideration, I believe that the paper has the potential to be published in a top-tier conference, but it requires further refinement and improvement.\n\n**Recommendation:**\n\nI recommend that the paper be accepted for publication, but with the following conditions:\n\n1. The authors should provide additional theoretical results to support the proposed method.\n2. The authors should address the complexity concerns by providing a more detailed analysis of the computational complexity.\n3. The authors should expand the experimental results to include other evaluation tasks, such as graph reconstruction and link prediction.\n4. The authors should consider alternative approaches to Chebyshev polynomials to improve efficiency.\n\n**Final Decision:** Accept"
    },
    {
      "paper_id": "9GUTgHZgKCH",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\n1. **Lack of clarity and organization**: The paper is not well-written, and the presentation needs considerable improvement. The authors have acknowledged this and agreed to rethink how to make the text more readable.\n2. **Insufficient experimental evaluation**: The experiments are not convincing, and the authors have agreed to conduct more experiments, including comparisons with state-of-the-art pruning techniques and more complex datasets.\n3. **Unpublished work**: The paper heavily relies on unpublished work, which makes it difficult to evaluate the correctness and validity of the proposed algorithm. The authors have agreed to publish the other paper first and provide a clear reference.\n4. **Similarities with existing work**: The proposed algorithm is similar to existing pruning techniques, such as highway networks, and the authors have acknowledged this.\n5. **Theory-driven approach**: The authors claim that their algorithm is highly theory-driven, but the theory is not clearly explained, and the connection between the theory and the algorithm is not well-established.\n6. **Typos and grammatical errors**: The paper contains numerous typos and grammatical errors, which detract from the overall quality of the paper.\n7. **Lack of comparison with standard baselines**: The authors have agreed to compare their method with standard baselines, but this has not been done yet.\n8. **Computational complexity**: The authors have provided an estimate of the computational complexity of their algorithm, but it is not clear whether this is accurate or efficient.\n\nConsidering these points, I have the following concerns:\n\n* The paper lacks clarity and organization, which makes it difficult to understand and evaluate the proposed algorithm.\n* The experimental evaluation is insufficient, and the authors need to conduct more experiments to demonstrate the effectiveness of their algorithm.\n* The reliance on unpublished work makes it difficult to evaluate the correctness and validity of the proposed algorithm.\n* The similarities with existing work and the lack of clear explanation of the theory-driven approach raise concerns about the novelty and originality of the paper.\n\nHowever, the authors have acknowledged these concerns and have agreed to address them. They have also provided additional information and explanations in their responses, which has helped to clarify some of the issues.\n\nBased on these observations and concerns, I recommend the following:\n\n**Final Decision: Reject**\n\nWhile the authors have made efforts to address the concerns, the paper still requires significant revisions to address the issues mentioned above. The lack of clarity, insufficient experimental evaluation, and reliance on unpublished work make it difficult to evaluate the paper's contributions and novelty. The authors need to provide a more comprehensive and well-written paper that addresses these concerns and demonstrates the effectiveness and originality of their algorithm."
    },
    {
      "paper_id": "JzG0n48hRf",
      "source": "ICLR 2021",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths of the paper:\n\n1. The paper addresses an important problem in deep learning, namely, the issue of over-confident predictions on out-of-distribution (OOD) data.\n2. The proposed methods, Single Image and Multiple Image Method, are novel and seem to be effective in improving calibration on OOD data.\n3. The experiments demonstrate that the methods can consistently improve calibration across different corruptions.\n4. The paper provides a clear and concise introduction to the problem and the proposed methods.\n\nWeaknesses of the paper:\n\n1. The paper relies on a pre-specified set of corruptions to generate the validation data, which may not be generalizable to other types of corruptions.\n2. The results are only reported when the validation corruption is \"Contrast\", and it would be interesting to see how the method performs on other types of corruptions.\n3. The paper does not provide a clear explanation of why the \"Multiple Image Method\" is used, and how it can be sure that the images come from the same distribution.\n4. The notation is not always clear, and some equations are not well-defined.\n5. The paper does not provide a thorough evaluation of the method on completely OOD data, such as using SVHN dataset for testing predictions of a model that was trained on CIFAR-10.\n\nReviewer comments and author responses:\n\n1. Reviewer 1 pointed out that the approach assumes the possible novel distributions are known, which is not assumed in existing work. However, the authors clarified that they do not assume to know which \"unknown distribution\" the novel image is from, but rather use a pre-specified set of corruptions to generate the validation data.\n2. Reviewer 2 suggested that the motivation for the \"Multiple Image Method\" is less clear and that a weighted averaging approach could be used instead. The authors responded that they do compare the distribution of pmax values, but use the mean instead of KL-divergence for simplicity.\n3. Reviewer 3 pointed out that the terminology is ill-defined and that the notation is not always clear. The authors responded by clarifying the terminology and notation, and providing additional explanations in the revised version of the paper.\n4. Reviewer 4 suggested that the paper would be more interesting if it showed calibration advantages on more than just artificially corrupted sets. The authors responded by adding results on completely OOD data, such as using SVHN dataset for testing predictions of a model that was trained on CIFAR-10.\n\nBased on the above analysis, I conclude that the paper has some strengths, but also some weaknesses that need to be addressed. The paper provides a clear and concise introduction to the problem and the proposed methods, and the experiments demonstrate that the methods can consistently improve calibration across different corruptions. However, the paper relies on a pre-specified set of corruptions to generate the validation data, and the results are only reported when the validation corruption is \"Contrast\". Additionally, the notation is not always clear, and some equations are not well-defined.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "fuYtttFI-By",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper presents a novel approach to 3D snapshot microscopy using Fourier convolutional neural networks, which enables efficient global convolutions and handles large PSFs.\n2. The authors demonstrate the effectiveness of their approach on simulated data and real-world experiments, including lensless imaging.\n3. The paper has a clear and well-structured presentation, with a thorough limitations section.\n4. The authors address the concerns raised by the reviewers, providing additional implementation details and clarifying the differences between their approach and previous work.\n\nWeaknesses:\n\n1. The paper lacks a clear comparison with previous work, particularly Rippel et al. (2015), which introduced similar ideas.\n2. The evaluation is limited to simulated data, and the authors acknowledge the need for real-world experiments.\n3. The results from UNet are unclear, and the authors do not provide a clear explanation for the differences between their approach and UNet.\n4. The paper has limited technical novelty, as the idea of using Fourier-domain networks is not new.\n\nReviewer comments:\n\n1. Reviewer 1 and Reviewer 2 have positive comments, but Reviewer 1 suggests that the evaluation can be improved.\n2. Reviewer 3 has a mixed opinion, suggesting that the paper is good but not suitable for ICLR.\n3. Reviewer 4 has significant concerns about the paper's technical novelty and significance.\n4. Reviewer 5 has concerns about the evaluation and the explanation of UNet results.\n5. Reviewer 6 has positive comments but raises questions about the claimed contributions.\n6. Reviewer 7 has a mixed opinion, suggesting that the paper is well-written but lacks technical novelty.\n\nAuthor responses:\n\n1. The authors address the concerns raised by the reviewers, providing additional implementation details and clarifying the differences between their approach and previous work.\n2. The authors acknowledge the limitations of their evaluation and suggest that real-world experiments are needed to validate their approach.\n\nBased on the detailed reasoning above, I conclude that the paper has some strengths, but also significant weaknesses and limitations. While the authors address the concerns raised by the reviewers, the paper still lacks a clear comparison with previous work, and the evaluation is limited to simulated data.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "MTsBazXmX00",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author response, I have the following detailed reasoning:\n\n**Strengths of the paper:**\n\n1. The paper proposes a novel approach to target propagation, which is an interesting alternative to backpropagation.\n2. The authors provide a clear and structured presentation of their method, making it easy to follow.\n3. The paper demonstrates the effectiveness of the proposed algorithm on recurrent neural networks with long sequences.\n\n**Weaknesses of the paper:**\n\n1. The paper lacks theoretical guarantees that the proposed algorithm is better than backpropagation. Reviewer 1 points out that the algorithm's guarantees are not sufficiently strong.\n2. The experimental results are not convincing, as mentioned by Reviewer 1. The paper shows improvement compared to gradient descent, but the improvements are not fully explained from the theoretical side.\n3. The paper has limited comparison with other learning algorithms designed to improve learning in RNNs. Reviewer 4 suggests that the paper needs to explain more about what is different in the optimization to make it work better and evaluate how robust those improvements are with more detailed and extensive experimentation.\n4. The paper has minor issues with claims and statements, as pointed out by Reviewer 1 and Reviewer 4.\n\n**Reviewer comments:**\n\n1. Reviewer 1 is not enthusiastic about the paper, citing that the algorithm loses most of the features that make target propagation attractive as an alternative to backpropagation.\n2. Reviewer 2 finds the paper novel and interesting, but has some concerns about the experimental results.\n3. Reviewer 3 is not convinced by the paper's superiority over backpropagation and suggests that the authors should provide more competitive results.\n4. Reviewer 4 finds the paper interesting but needs more theoretical properties and detailed experimentation and comparisons.\n\n**Author response:**\n\nUnfortunately, there is no author response provided, which makes it difficult to address the reviewers' concerns and provide a clear explanation of the paper's contributions.\n\n**Conclusion:**\n\nBased on the detailed analysis, I conclude that the paper has some interesting ideas, but it lacks sufficient theoretical guarantees, experimental evidence, and comparison with other learning algorithms. The paper also has minor issues with claims and statements. Given the top-tier conference standards, I believe that the paper needs more work to address these concerns.\n\n**Final Decision: Reject**\n\nThe paper has some interesting ideas, but it falls short of the top-tier conference standards due to its limitations in theoretical guarantees, experimental evidence, and comparison with other learning algorithms. With some revisions addressing these concerns, the paper may be considered for publication in a lower-tier conference or a journal."
    },
    {
      "paper_id": "xspalMXAB0M",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel approach to reinforcement learning (RL) using boosting techniques, which is an interesting and significant contribution.\n2. The authors provide a rigorous theoretical analysis of the proposed algorithm, including sample complexity and running time bounds that are polynomial in the natural parameters of the problem.\n3. The paper uses a non-convex variant of the Frank-Wolfe method, which is a novel application of this technique in the context of RL.\n4. The authors provide a clear and well-structured presentation of the paper, making it easy to follow.\n\n**Weaknesses:**\n\n1. The paper is notation-heavy, which can make it difficult for readers to understand the results and contributions.\n2. The authors assume access to a weak learner, which is a restrictive assumption that may not be easily verifiable in practice.\n3. The paper does not provide empirical results to validate the effectiveness of the proposed algorithm.\n4. Some of the reviewer comments suggest that the paper's contributions are not entirely novel, as similar ideas have been explored in previous work (e.g., Hazan and Singh 2021).\n\n**Author Responses:**\n\nThe authors have addressed many of the reviewer comments, including clarifying the notation, providing additional intuition for the algorithm, and discussing the assumptions made in the paper. However, some of the reviewer comments remain unaddressed, such as the lack of empirical results and the comparison with no-boosting RL approaches.\n\n**Final Decision:**\n\nBased on the strengths and weaknesses of the paper, as well as the author responses, I recommend **Acceptance** with minor revisions. The paper makes a significant contribution to the field of RL by proposing a novel approach using boosting techniques, and the authors provide a rigorous theoretical analysis of the proposed algorithm. However, the paper would benefit from additional clarity and notation, as well as empirical results to validate the effectiveness of the proposed algorithm.\n\nTo ensure that the paper meets the standards of a top-tier conference, I recommend that the authors:\n\n1. Revise the paper to improve clarity and notation.\n2. Provide empirical results to validate the effectiveness of the proposed algorithm.\n3. Address the remaining reviewer comments, including the comparison with no-boosting RL approaches.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "SgEhFeRyzEZ",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths of the paper:\n\n1. The paper provides a rigorous theoretical analysis of the Feedback Alignment (FA) algorithm, which is an efficient alternative to backpropagation for training neural networks.\n2. The authors provide convergence guarantees with rates for deep linear networks for both continuous and discrete dynamics.\n3. The paper studies incremental learning phenomena for shallow linear networks and identifies an interesting implicit anti-regularization phenomenon.\n4. The authors propose initialization schemes where the components of the problem are approximately learned by decreasing order of importance, thus providing a form of implicit regularization.\n\nWeaknesses of the paper:\n\n1. The reviewer comments highlight that the one-dimensional setting may oversimplify the original problem, and the novelty may not be significant enough.\n2. Reviewer 2 points out that the convergence results assume strong conditions that only work for specific cases.\n3. Reviewer 4 raises concerns about the significance of the results since they are under spectral initialization, which is rarely used in practice.\n4. Reviewer 4 also suggests that the results are hard to interpret in general non-spectral settings.\n\nAuthor responses:\n\n1. The authors address the concerns of Reviewer 4 by clarifying the spectral initialization assumption and providing additional experiments under non-spectral initialization.\n2. The authors also provide additional details and explanations to address the concerns of Reviewer 2 and Reviewer 3.\n\nBased on the reviewer comments and author responses, I conclude that the paper has some strengths, but also some weaknesses that need to be addressed. While the paper provides a rigorous theoretical analysis of the FA algorithm, the reviewer comments highlight that the one-dimensional setting may oversimplify the original problem, and the novelty may not be significant enough.\n\nHowever, the author responses address some of the concerns raised by the reviewers, and the paper provides some interesting insights into the behavior of the FA algorithm.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "morSrUyWG26",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper presents a well-designed and user-friendly platform for optimal experimental design (OED) with multi-objective Bayesian optimization (MOBO).\n2. The authors have implemented a novel strategy called Believer-Penalizer (BP) for asynchronous parallel optimization, which is a significant contribution.\n3. The paper provides a clear and concise explanation of the platform's design principles, functionalities, and performance.\n4. The authors have conducted extensive evaluations on 12 benchmark problems using 20 random seeds with several ablation studies, which demonstrates the robustness of the platform.\n\nWeaknesses:\n\n1. The paper is more system-oriented, and some reviewers have questioned the novelty and significance of the contributions.\n2. The authors have not provided a clear theoretical justification for the BP strategy, which is a limitation.\n3. The paper has some minor issues with correctness, such as typos and inconsistencies in notation.\n4. Some reviewers have pointed out that the platform is limited to 2 or 3 objectives, which is a significant limitation.\n\nAuthor responses:\n\nThe authors have addressed many of the concerns raised by the reviewers, including the novelty and significance of the contributions, the theoretical justification for BP, and the limitations of the platform. However, some concerns remain, such as the lack of a clear theoretical proof for BP and the limited scope of the platform.\n\nConclusion:\n\nBased on the strengths and weaknesses of the paper, as well as the author responses, I conclude that the paper should be accepted for publication. While the paper has some limitations, it presents a significant contribution to the field of OED and MOBO, and the authors have addressed many of the concerns raised by the reviewers. The paper is well-written, and the authors have provided a clear and concise explanation of the platform's design principles, functionalities, and performance.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "Z7Lk2cQEG8a",
      "source": "ICLR 2022",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I conclude that the paper should be accepted for publication.\n\nHere's my detailed reasoning:\n\nStrengths of the paper:\n\n1. The paper provides a novel and significant contribution to the field of neural networks, specifically for two-layer ReLU networks. The authors prove that finding all globally optimal solutions can be performed by solving a convex optimization program with cone constraints.\n2. The paper introduces a new concept of \"nearly minimal\" neural networks, which provides a simple structure for the set of 2-layer ReLU neural networks and is directly related to the solutions to the convex program.\n3. The authors provide a polynomial-time algorithm for checking if a neural network is globally optimal, which is a significant result.\n4. The paper establishes that Clarke stationary points found by stochastic gradient descent correspond to the global optimum of a subsampled convex problem, which provides insight into the behavior of gradient descent.\n\nWeaknesses and limitations:\n\n1. The paper only considers two-layer ReLU networks, which is a limitation. However, the authors provide a clear explanation of why this is the case and mention that they are working on extending the results to deep neural networks.\n2. The paper relies on the convex optimization formulation of the regularized training problem, which may not be directly applicable to other activation functions. However, the authors mention that they are working on extending the method to other activation functions.\n\nReviewer comments:\n\n1. Reviewer 1 provides a detailed and balanced review, highlighting both the strengths and weaknesses of the paper.\n2. Reviewer 2 provides a very positive review, highlighting the significance and novelty of the paper.\n3. Reviewer 3 provides a more critical review, pointing out that the paper builds on previous work and that the results may not be directly applicable to deep neural networks.\n4. Reviewer 4 provides a very positive review, highlighting the significance and novelty of the paper.\n\nAuthor responses:\n\n1. The authors provide clear and detailed responses to the reviewer comments, addressing the concerns and providing additional information.\n2. The authors mention that they are working on extending the results to deep neural networks and other activation functions.\n\nConclusion:\n\nBased on the strengths and weaknesses of the paper, as well as the reviewer comments and author responses, I conclude that the paper should be accepted for publication. The paper provides a significant contribution to the field of neural networks, specifically for two-layer ReLU networks, and the authors have addressed the concerns raised by the reviewers. The paper has the potential to inspire further research and development in the field.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "Dy8gq-LuckD",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\n1. **Interesting research topic**: The paper explores an important issue in multi-modal learning, where models tend to rely on one modality while under-utilizing the other modalities. This phenomenon is observed in various tasks and architectures, making it a relevant and timely research topic.\n2. **Empirical validation**: The authors provide empirical evidence to support their claims, including experiments on multiple datasets and tasks. The results show that the proposed method, balanced multi-modal learning, improves the model's generalization performance and reduces the greedy behavior.\n3. **Methodological contributions**: The paper introduces a new metric, conditional learning speed, to measure the imbalance in modality utilization. The authors also propose a training algorithm, balanced multi-modal learning, to address the issue of greedy learning.\n4. **Weaknesses and limitations**: Reviewers have pointed out several weaknesses and limitations, including:\n\t* Lack of theoretical analysis to support the greedy learner hypothesis.\n\t* Insufficient comparison with other methods that solve the imbalance problem.\n\t* Limited discussion of related work and comparison with state-of-the-art methods.\n\t* Lack of ablation study on the hyperparameters introduced in the proposed algorithm.\n\t* Limited evaluation on datasets with natural modalities (e.g., audio-visual datasets).\n5. **Author responses**: The authors have addressed some of the concerns raised by the reviewers, including providing additional experimental results, clarifying the re-balancing step, and discussing the limitations of their work.\n\nConsidering these points, I believe that the paper has made significant contributions to the field of multi-modal learning, and the authors have addressed some of the concerns raised by the reviewers. However, there are still some weaknesses and limitations that need to be addressed.\n\n**Final Decision: Accept**\n\nI recommend accepting the paper for publication, subject to the authors addressing the remaining concerns and weaknesses. The authors should provide a more thorough theoretical analysis to support the greedy learner hypothesis, compare their method with other state-of-the-art methods, and conduct a more comprehensive ablation study on the hyperparameters. Additionally, they should evaluate their method on datasets with natural modalities and provide a more detailed discussion of the related work. With these improvements, the paper will be more comprehensive and impactful, and its contributions will be more clearly established."
    },
    {
      "paper_id": "VFBjuF8HEp",
      "source": "ICLR 2022",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I conclude that the paper should be accepted for publication.\n\nHere's my detailed reasoning:\n\n1. **The paper addresses an important problem**: The paper tackles the issue of accelerating diffusion models, which is a significant challenge in the field of generative models. The authors propose a novel method, Differentiable Diffusion Sampler Search (DDSS), to optimize the sampling process, leading to improved sample quality and reduced inference time.\n2. **The method is well-motivated**: The authors provide a clear connection between their perceptual loss and the Kernel Inception Distance (KID), which is a well-established metric for evaluating generative models. This connection helps to motivate their choice of loss function and provides a clear understanding of what the method is optimizing for.\n3. **The empirical results are strong**: The authors provide a comprehensive set of experiments demonstrating the effectiveness of their method. The results show significant improvements in sample quality and reduced inference time compared to existing methods, such as DDPM and DDIM.\n4. **The authors address reviewer concerns**: The authors have carefully addressed the concerns raised by the reviewers, providing additional explanations, empirical evidence, and clarifications to strengthen the paper.\n5. **The paper has a clear and concise writing style**: The authors have revised the paper to improve its clarity and concision, making it easier for readers to understand the method and its implications.\n\nHowever, there are some minor issues that the authors could address in the final version:\n\n1. **Some equations could be clarified**: A few equations, such as Equation (2) and Equation (9), could be clarified to make them easier to understand.\n2. **More details on the parameterization**: The authors could provide more details on the parameterization of the GGDM model, which would help readers understand the method better.\n3. **More experiments on larger datasets**: While the authors have provided experiments on CIFAR and ImageNet, it would be beneficial to include more experiments on larger datasets, such as LSUN and CelebA, to demonstrate the method's effectiveness on more challenging tasks.\n\nOverall, I believe that the paper has made significant progress in addressing the challenges of accelerating diffusion models, and the authors have provided a clear and well-motivated method. With some minor revisions, the paper will be even stronger and more impactful.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "5ECQL05ub0J",
      "source": "ICLR 2022",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I conclude that the paper should be accepted for publication.\n\nHere's my detailed reasoning:\n\nStrengths of the paper:\n\n1. The paper tackles an important and timely problem in machine learning, specifically the convergence of stochastic gradient descent with momentum (SGDm) under non-iid sampling.\n2. The authors provide a novel connection between nonlinear resonance theory and machine learning, which is a significant contribution to the field.\n3. The paper is well-written, and the authors have made a concerted effort to address the reviewers' comments and concerns.\n4. The empirical results are comprehensive and demonstrate the resonance phenomenon in various settings, including linear regression and neural networks.\n\nWeaknesses of the paper:\n\n1. Some reviewers have raised concerns about the novelty and significance of the technical contributions, particularly the use of existing results from numerical analysis and Floquet theory.\n2. The presentation and discussion of Theorem 1 have been criticized for being unclear and lacking intuition.\n3. The analysis is carried out using expected gradients, which some reviewers have questioned as being relevant to stochastic descent algorithms.\n\nAddressing the weaknesses:\n\n1. The authors have acknowledged the concerns about novelty and significance and have softened their language to reflect the connection between nonlinear resonance theory and machine learning.\n2. The authors have provided additional intuition and explanations to clarify the presentation and discussion of Theorem 1.\n3. The authors have addressed the concerns about expected gradients by providing additional experimental results and ablation studies to demonstrate the relevance of their analysis to stochastic descent algorithms.\n\nOverall, while the paper has some weaknesses, the authors have made a significant effort to address the reviewers' comments and concerns. The paper's contributions to the field of machine learning are substantial, and the empirical results are comprehensive and convincing.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "eOdSD0B5TE",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper presents novel and elegant theoretical results on the average error of the solution space, which is a significant contribution to the field.\n2. The authors develop new technical tools to analytically bound and consistently estimate the average test error of the neural network-Gaussian process (NNGP) posterior, which is a valuable contribution.\n3. The paper explores the connection between large margin functions and generalization, which is an important area of research.\n4. The authors provide a clear and well-written paper that is easy to follow.\n\n**Weaknesses:**\n\n1. The experimental evaluation is limited, and the authors rely on a specific setting (Nero optimizer, mini-batching, and learning rate decay) that may not be representative of the general case.\n2. The analysis of the implicit bias of gradient descent is not rigorous and may be misleading, as pointed out by Reviewer 5.\n3. The paper overpromises analysis of both the implicit bias of neural architecture and the implicit bias of gradient descent, while providing only analysis of the implicit bias of neural architecture under a Gaussian process.\n4. The bounds obtained by the theoretical derivation are only slightly better than chance, and there is a significant gap between the bounds and empirical results.\n5. The paper does not provide a comprehensive comparison of different architectures, and the comparison between depth 2 and 7 is preliminary.\n\n**Reviewer comments:**\n\n1. Reviewer 1 finds the paper interesting but notes that the experiments show the bounds are very loose and do not have much practical significance.\n2. Reviewer 2 agrees that the paper is interesting but notes that the implicit bias of GD is more appropriately described as the implicit bias of overfitting.\n3. Reviewer 3 finds the paper premature in its current form and suggests that more concise writing, focusing only on the implicit bias of NNGP, with more comprehensive experiments would be a good submission worthy of publication.\n4. Reviewer 4 finds the paper's claims about margin to be not rigorous and raises doubts on the validity of the entire submission.\n5. Reviewer 5 agrees that the paper contains interesting theoretical results but notes that the experiments are limited and the analysis of the implicit bias of gradient descent is not rigorous.\n6. Reviewer 6 finds the paper overpromises analysis of both the implicit bias of neural architecture and the implicit bias of gradient descent, while providing only analysis of the implicit bias of neural architecture under a Gaussian process.\n7. Reviewer 7 finds the paper's main finding, namely the huge disparity between the GD NN and NNGP in section 5.2, to be novel and thought-provoking but notes that the experimental evidence is limited.\n8. Reviewer 8 finds the paper's main contribution to be incremental and notes that the rest of the analysis does not provide novel and relevant insights.\n9. Reviewer 9 finds the paper to be well-written and easy to follow but notes that the experimental validation could be improved.\n\n**Author responses:**\n\n1. The authors clarify that the language surrounding the \"implicit bias of gradient descent\" might be misleading and plan to revise it for clarity.\n2. The authors respond to Reviewer 5's concerns about the analysis of the implicit bias of gradient descent and clarify that they are not claiming that gradient descent maximizes margin in all cases.\n3. The authors respond to Reviewer 7's concerns about the experimental evidence and clarify that their claim is that large margin functions generalise better for both NNGP and GD-trained neural nets.\n\n**Conclusion:**\n\nBased on the strengths and weaknesses of the paper, as well as the reviewer comments and author responses, I conclude that the paper should be **Rejected** for publication at a top-tier conference. While the paper presents novel and elegant theoretical results, the experimental evaluation is limited, and the analysis of the implicit bias of gradient descent is not rigorous. The paper also overpromises analysis of both the implicit bias of neural architecture and the implicit bias of gradient descent, while providing only analysis of the implicit bias of neural architecture under a Gaussian process. Additionally, the bounds obtained by the theoretical derivation are only slightly better than chance, and there is a significant gap between the bounds and empirical results.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "7gRvcAulxa",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\n**Strengths:**\n\n1. The paper presents an interesting and novel perspective on adversarial examples, challenging the common misconception that they are high-frequency noise.\n2. The authors provide a comprehensive analysis of the frequency properties of adversarial examples, using both theoretical and empirical findings.\n3. The paper explores the implications of frequency analysis on adversarial training, proposing a new framework to measure robustness.\n4. The authors have responded to most of the reviewer comments, addressing concerns and providing additional information.\n\n**Weaknesses:**\n\n1. Some reviewers have raised concerns about the novelty and significance of the contributions, suggesting that they are not well-supported or are too general.\n2. The paper relies heavily on existing work, and the authors' claims may not be entirely new or original.\n3. The experimental design and results are not always clear, and some reviewers have questioned the methodology and conclusions.\n4. The paper does not provide a clear explanation of how the frequency-based approach can be used to improve adversarial robustness or accuracy.\n\n**Reviewer comments:**\n\n1. Reviewer 1 has raised concerns about the lack of consideration of universal adversarial perturbations (UAPs) and the need to improve the work by taking UAPs into account.\n2. Reviewer 2 has questioned the clarity of the contributions and the novelty of the work, suggesting that the authors should provide more details about how their analysis can help existing research and future works.\n3. Reviewer 3 has raised concerns about the motivation and justification of the work, suggesting that the authors should better address the common misconception about high-frequency noise.\n4. Reviewer 4 has praised the paper's insights and practical consequences but has raised concerns about the presentation of figures and minor grammatical errors.\n\n**Author responses:**\n\n1. The authors have responded to most of the reviewer comments, addressing concerns and providing additional information.\n2. They have clarified their contributions, highlighting the novelty and significance of their work.\n3. They have provided additional experimental results and explanations to support their claims.\n\n**Conclusion:**\n\nBased on the analysis of the paper, reviewer comments, and author responses, I conclude that the paper has some strengths, but also significant weaknesses. While the authors have made an effort to address the reviewer comments, some concerns remain about the novelty and significance of the contributions, the clarity of the experimental design and results, and the potential impact of the frequency-based approach on adversarial robustness or accuracy.\n\n**Final Decision:**\n\nAccept with minor revisions.\n\nThe paper has the potential to contribute to the field of adversarial robustness, and the authors have made a good effort to address the reviewer comments. However, to make the paper more convincing, the authors should:\n\n1. Clarify the novelty and significance of their contributions.\n2. Provide more details about how their analysis can help existing research and future works.\n3. Address the concerns about the experimental design and results.\n4. Provide a clear explanation of how the frequency-based approach can be used to improve adversarial robustness or accuracy.\n\nWith minor revisions, the paper can be accepted for publication."
    },
    {
      "paper_id": "CES-KyrKcTM",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\n1. **Theoretical contributions**: The paper presents a novel framework for robust optimization using the weighted mean trick. However, the reviewer comments highlight several issues with the theoretical contributions, including:\n\t* The paper assumes the existence of the first moment of the loss function, which may not hold for heavy-tailed distributions.\n\t* The statement of Lemma 2 is unclear, and the reviewer questions the convexity of the objective function.\n\t* The paper does not provide a clear connection between the weighted mean trick and robustness.\n2. **Empirical results**: The paper presents experimental results that show the weighted mean trick performs similarly to other robust loss functions. However, the reviewer comments highlight concerns about the empirical novelty and significance of the results.\n3. **Clarity and readability**: The paper has some issues with clarity and readability, including:\n\t* The notation is not consistently used throughout the paper.\n\t* Some sections are written without proper explanation.\n\t* The paper could benefit from a clearer introduction and motivation.\n4. **Comparison to existing work**: The paper does not provide a clear comparison to existing work in the field of robust optimization. The reviewer comments highlight the need for a more thorough comparison to existing methods.\n\nConsidering these observations and concerns, I believe that the paper has some potential but requires significant revisions to address the issues mentioned above. The authors have made some efforts to address the reviewer comments, but more work is needed to ensure that the paper meets the standards of a top-tier conference.\n\n**Final Decision: Reject**\n\nThe paper has some interesting ideas, but the theoretical contributions are not well-supported, and the empirical results are not novel or significant enough to justify publication in a top-tier conference. The paper requires significant revisions to address the issues mentioned above, including clarifying the notation, providing a clearer introduction and motivation, and comparing the results to existing work in the field."
    },
    {
      "paper_id": "VDdDvnwFoyM",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author response, I have the following detailed reasoning:\n\n**Strengths of the paper:**\n\n1. The paper proposes a novel architecture for synthetic time-series data generation using Variational Auto-Encoders (VAEs), which is a significant contribution to the field.\n2. The authors provide a clear and well-written paper that is easy to follow.\n3. The paper includes a comprehensive literature review and discusses the limitations of existing methods.\n4. The authors provide a detailed experimental evaluation on four multivariate datasets, which demonstrates the effectiveness of their proposed method.\n\n**Weaknesses of the paper:**\n\n1. The reviewer comments highlight several concerns, including the lack of evaluation of hyper-parameters, the limited empirical evaluation, and the unclear motivation for the proposed architecture.\n2. Reviewer 2 points out that the proposed method is not substantially original and does not provide any significant novelty compared to existing methods.\n3. Reviewer 3 raises several concerns about the literature review, background, and methods, which are not clearly described.\n4. Reviewer 4 doubts the practical value of the proposed method and questions its ability to capture the necessary needs for specific questions.\n\n**Author response:**\n\nUnfortunately, there is no author response provided, which makes it difficult to address the reviewer comments and concerns.\n\n**Final decision:**\n\nBased on the detailed analysis, I conclude that the paper should be **Rejected** for publication at a top-tier conference like ICLR. While the paper proposes a novel architecture and provides a comprehensive literature review, the reviewer comments highlight several significant concerns that need to be addressed. The lack of evaluation of hyper-parameters, limited empirical evaluation, and unclear motivation for the proposed architecture are major concerns that need to be addressed. Additionally, the reviewer comments raise questions about the practical value and novelty of the proposed method. Without an author response to address these concerns, it is difficult to recommend publication.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "VFBjuF8HEp",
      "source": "ICLR 2022",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I conclude that the paper should be accepted for publication.\n\nHere's my detailed reasoning:\n\n1. **Technical novelty and significance**: The paper introduces a new method, Differentiable Diffusion Sampler Search (DDSS), which optimizes fast samplers for diffusion models by differentiating through sample quality scores. This is a significant contribution to the field of generative models, as it allows for faster sampling and better quality retention.\n2. **Empirical results**: The paper presents strong empirical results, demonstrating that DDSS outperforms existing methods in terms of sample quality and inference speed. The results are consistent across various datasets, including CIFAR-10 and ImageNet 64x64.\n3. **Clarity and motivation**: While the original submission had some clarity issues, the author responses and revised paper address these concerns. The paper now clearly motivates the choice of perceptual loss and establishes a connection to the Kernel Inception Distance (KID).\n4. **Theoretical grounding**: The paper provides a theoretical framework for understanding the proposed method, including a proof sketch for Theorem 1. While the formal proof is moved to the appendix, it is still a significant contribution to the field.\n5. **Reviewer feedback**: The majority of reviewers (4 out of 5) provide positive feedback, with some minor concerns addressed in the author responses. Reviewer 1 raises some concerns about the motivation and theoretical grounding, but the author responses address these issues.\n\nHowever, I also note that:\n\n1. **Some reviewers have concerns**: Reviewer 1 and Reviewer 4 have some concerns about the motivation and theoretical grounding of the paper. While these concerns are addressed in the author responses, they are still valid points that need to be considered.\n2. **Some minor issues**: Reviewer 5 points out some minor issues with clarity and notation, which are addressed in the revised paper.\n\nOverall, I believe that the paper's technical novelty, empirical results, and clarity make it a strong candidate for publication. While there are some minor concerns and issues, they are addressed in the author responses and revised paper. Therefore, I recommend accepting the paper for publication.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "7zc05Ua_HOK",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel approach to adversarial robustness, which is a significant contribution to the field.\n2. The authors provide a clear and well-structured presentation of their method, making it easy to follow.\n3. The experimental results demonstrate the effectiveness of the proposed method in improving both clean and robust accuracy.\n4. The authors address several reviewer concerns and provide additional experiments to support their claims.\n\n**Weaknesses:**\n\n1. Some reviewers question the novelty of the proposed method, as it builds upon existing work in meta-learning and adversarial training.\n2. The paper lacks a thorough theoretical justification for the use of multi-class margins as input to the reweighting network.\n3. Some reviewers suggest that the performance improvement may be due to the increased capacity of the reweighting network rather than the specific input encoding used.\n4. The paper does not provide a comprehensive comparison with state-of-the-art baselines, particularly on CIFAR-100.\n\n**Author Responses:**\n\nThe authors address several reviewer concerns, including the novelty of their method, the use of multi-class margins, and the potential impact of the reweighting network's capacity. They provide additional experiments and clarify their approach, which helps to alleviate some of the concerns.\n\n**Final Decision:**\n\nBased on the strengths and weaknesses, as well as the author responses, I recommend **Acceptance** of the paper for publication. While the paper has some limitations, the proposed method is novel and effective, and the authors have addressed several reviewer concerns. The paper provides a valuable contribution to the field of adversarial robustness and will likely spark further research and discussion.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "RhB1AdoFfGE",
      "source": "ICLR 2022",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\nStrengths:\n\n1. The paper presents a novel approach to face detection, which is a significant problem in computer vision.\n2. The proposed method, SCRFD, achieves state-of-the-art accuracy-efficiency trade-off on the WIDER FACE dataset.\n3. The authors provide a detailed ablation study, which demonstrates the effectiveness of the proposed methods.\n4. The paper is well-written, and the authors have addressed most of the reviewer comments.\n\nWeaknesses:\n\n1. Some reviewers have raised concerns about the simplicity of the proposed methods, which may not be as novel or significant as claimed.\n2. The paper lacks a comparison with other state-of-the-art network search methods, which is a significant omission.\n3. The authors have not provided enough details about the sample distribution and the binary probability model.\n4. Some reviewers have pointed out minor issues with the paper's claims and statements.\n\nBased on these observations, I believe that the paper has some strengths, but also some weaknesses that need to be addressed. The proposed method is novel and effective, but its simplicity may not be as significant as claimed. The lack of comparison with other state-of-the-art network search methods is a significant omission, and the authors need to provide more details about the sample distribution and the binary probability model.\n\nHowever, the authors have addressed most of the reviewer comments, and the paper is well-written. The proposed method has achieved state-of-the-art accuracy-efficiency trade-off on the WIDER FACE dataset, which is a significant contribution.\n\nTherefore, I recommend accepting the paper for publication, but with some minor revisions to address the concerns raised by the reviewers.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "ffS_Y258dZs",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper and the reviewer comments, I have the following observations and concerns:\n\n1. **Clarity and readability**: The paper is difficult to follow, and the reviewers have pointed out several issues with clarity, including long sentences, repetitive text, and missing definitions. The authors need to improve the writing style and provide more concrete examples to make the paper more readable.\n2. **Technical novelty and significance**: The reviewers have questioned the technical novelty and significance of the paper. While the idea of compositional learning is interesting, the proposed method and benchmark may not be significantly new or impactful. The authors need to provide more evidence to support the claimed contributions.\n3. **Experimental design and results**: The reviewers have pointed out several issues with the experimental design and results, including the lack of ablation studies, insufficient details about the model architecture and training regimes, and poor performance of the proposed method. The authors need to improve the experimental design and provide more convincing results.\n4. **Engagement with the existing literature**: The reviewers have suggested that the paper needs to be better situated within the broader literature on compositional generalization. The authors need to engage more with the existing literature and clarify the contributions of their work.\n\nConsidering these concerns, I believe that the paper needs significant revisions to address the issues raised by the reviewers. While the idea of compositional learning is interesting, the current paper does not provide a strong enough case for publication in a top-tier conference.\n\n**Final Decision: Reject**\n\nHowever, I would recommend that the authors revise the paper based on the reviewer comments and resubmit it to the conference. With significant revisions, the paper may have a better chance of being accepted."
    },
    {
      "paper_id": "shbAgEsk3qM",
      "source": "ICLR 2022",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper provides a novel perspective on understanding the behavior of classical value estimation algorithms (TD, FVI, and RM) in the overparameterized linear case.\n2. The authors propose a unified interpretation of these algorithms as minimizing the Euclidean norm of the weights subject to alternative constraints.\n3. The paper provides a generalization bound for FVI and proposes two regularizers to improve the stability of TD and FVI in deep reinforcement learning.\n4. The authors have addressed most of the reviewer concerns and provided detailed responses.\n\nWeaknesses:\n\n1. Some reviewers have raised concerns about the setting used in the theoretical analysis, which relies on an IID dataset. However, the authors have provided a response addressing this concern.\n2. Reviewer 7 has pointed out that the paper does not give enough credit to existing results, particularly in Theorem 2, which is similar to a result in [1].\n3. Reviewer 7 has also mentioned that the Proof of Theorem 4 in the appendix includes mistakes and that the result is not novel.\n4. Reviewer 9 has pointed out errors in the paper, including incorrect derivations and missing explanations.\n5. Some reviewers have suggested that the paper's results are not significant or novel, particularly in the context of deep reinforcement learning.\n\nOverall, while the paper has some strengths, it also has several weaknesses that need to be addressed. The authors have made an effort to respond to the reviewer concerns, but some issues remain.\n\nFinal Decision: Accept\n\nI recommend accepting the paper for publication, but with the following conditions:\n\n1. The authors should address the concerns raised by Reviewer 7 regarding the lack of credit to existing results and the mistakes in the proof of Theorem 4.\n2. The authors should correct the errors pointed out by Reviewer 9 and provide clear explanations for the derivations.\n3. The authors should provide more discussion on the implications of the results in the context of deep reinforcement learning and the limitations of the overparameterized linear setting.\n4. The authors should consider extending the results to non-linear function approximation using neural tangent kernels, as suggested by Reviewer 10.\n\nBy addressing these concerns and conditions, the paper can be improved and published in the conference."
    },
    {
      "paper_id": "qfLJBJf_DnH",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths of the paper:\n\n1. The paper addresses an important problem in machine learning, specifically the issue of hierarchical control of continually learned autonomous motor motifs.\n2. The authors propose a novel approach inspired by the thalamocortical circuit, which shows promise in improving the accuracy and robustness of RNNs for this task.\n3. The paper provides a clear and concise introduction to the problem and the proposed solution, making it accessible to a broad audience.\n4. The authors have addressed many of the reviewer comments, providing additional evidence and clarifications to support their claims.\n\nWeaknesses of the paper:\n\n1. Some reviewers have raised concerns about the novelty and significance of the contributions, suggesting that they are only marginally significant or novel.\n2. The paper relies heavily on a specific task and dataset, which may limit its generalizability to other domains.\n3. The authors have not fully addressed the concerns about the relevance of the work to the broader field, with some reviewers suggesting that the scale of the experiments is too small to be meaningful.\n4. The paper could benefit from more detailed explanations of the theoretical foundations and the implications of the results.\n\nBased on these strengths and weaknesses, I would recommend the following:\n\nFinal Decision: Accept with minor revisions\n\nThe paper presents a novel and promising approach to hierarchical control of continually learned autonomous motor motifs, and the authors have addressed many of the reviewer comments. However, to further strengthen the paper, I would recommend the following minor revisions:\n\n1. Provide more detailed explanations of the theoretical foundations and the implications of the results.\n2. Address the concerns about the relevance of the work to the broader field, including the scale of the experiments.\n3. Provide more evidence to support the claims about the novelty and significance of the contributions.\n4. Consider adding more context and background information to help readers understand the significance of the problem and the proposed solution.\n\nOverall, the paper has the potential to make a significant contribution to the field, and with these minor revisions, it can be further strengthened to make a more compelling case for its importance and impact."
    },
    {
      "paper_id": "oiZJwC_fyS",
      "source": "ICLR 2022",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper presents a novel theoretical contribution to neural network approximation using tropical geometry, which is a new perspective on ReLU networks.\n2. The authors provide a clear and well-explained background on tropical geometry, making the paper accessible to non-domain experts.\n3. The paper proposes a geometrical approach for neural network compression, which is a significant contribution to the field.\n4. The authors provide theoretical bounds on the error of the approximation of their algorithms, which is a valuable contribution.\n\n**Weaknesses:**\n\n1. The experimental section has limitations, as the authors only evaluate their methods on small architectures and datasets (MNIST, Fashion-MNIST, and CIFAR-10/100).\n2. The authors do not compare their methods with more modern and complex architectures, such as ResNets, Vision Transformers, or larger datasets (COCO, ImageNet).\n3. The paper lacks a clear discussion on the computational and storage complexity of the proposed methods.\n4. The authors do not provide a clear comparison with other pruning methods, such as Alfarra et al. (2020), which is an unstructured pruning method.\n5. The paper has some minor issues with the presentation, such as unclear captions to tables and figures.\n\n**Author Response:**\n\nThe authors have addressed most of the reviewer comments and concerns, including:\n\n1. Clarifying the scope of their work and the limitations of their experiments.\n2. Providing a new theorem that gives a bound for neural network approximation.\n3. Changing the title of the paper to a more appropriate one.\n4. Making clear that their method lies in the area of structured pruning and is not comparable to unstructured pruning methods.\n\n**Conclusion:**\n\nWhile the paper has some limitations and minor issues, the authors have made significant efforts to address the reviewer comments and concerns. The novel theoretical contribution, clear presentation, and well-explained background on tropical geometry make the paper a valuable contribution to the field. However, the experimental section has limitations, and the authors should be encouraged to extend their work to more complex architectures and larger datasets.\n\n**Final Decision:**\n\nAccept\n\nThe paper presents a novel theoretical contribution to neural network approximation using tropical geometry, which is a significant contribution to the field. While the experimental section has limitations, the authors have made efforts to address the reviewer comments and concerns. With some minor revisions to address the remaining issues, the paper is suitable for publication in a top-tier conference."
    },
    {
      "paper_id": "JmU7lyDxTpc",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I conclude that the paper should be accepted for publication.\n\nHere's my detailed reasoning:\n\nStrengths of the paper:\n\n1. **Original contribution**: The paper presents a novel theoretical framework for understanding epoch-wise double descent in neural networks, which is a significant contribution to the field.\n2. **Clear and concise writing**: The authors have done an excellent job of explaining complex concepts in a clear and concise manner, making the paper accessible to a broad audience.\n3. **Empirical validation**: The authors provide empirical evidence to support their theoretical findings, which adds credibility to their results.\n4. **Relevant to the field**: The paper addresses an important open question in the field of deep learning and provides new insights into the behavior of neural networks.\n\nWeaknesses of the paper:\n\n1. **Technical complexity**: The paper assumes a strong background in statistical physics and random matrix theory, which may make it challenging for non-experts to follow.\n2. **Limited scope**: The paper focuses on a specific type of neural network (linear teacher-student model) and may not be generalizable to other types of networks.\n3. **Some minor errors**: The authors have made some minor errors in their derivations, which have been pointed out by the reviewers.\n\nAddressing reviewer comments:\n\n1. **Reviewer 1**: The authors have addressed the reviewer's concerns about the technical advancements and connections to prior work.\n2. **Reviewer 2**: The authors have discussed the connections to pioneering work and provided additional experiments to support their claims.\n3. **Reviewer 3**: The authors have addressed the reviewer's concerns about the technical advancements and provided additional clarification on the assumptions made in their derivations.\n\nAuthor responses:\n\n1. **Clear and concise responses**: The authors have provided clear and concise responses to the reviewers' comments, addressing each concern and providing additional clarification where necessary.\n2. **Minor errors corrected**: The authors have corrected the minor errors pointed out by the reviewers.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "morSrUyWG26",
      "source": "ICLR 2022",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper presents a well-designed and user-friendly platform for optimal experimental design (OED) with multi-objective Bayesian optimization (MOBO).\n2. The authors have implemented a novel strategy called Believer-Penalizer (BP) for asynchronous parallel optimization, which is a significant contribution.\n3. The paper provides a clear and concise explanation of the platform's design principles, functionalities, and performance.\n4. The authors have conducted extensive evaluations on 12 benchmark problems using 20 random seeds with several ablation studies, which demonstrates the robustness of the platform.\n\n**Weaknesses:**\n\n1. The paper is more system-oriented, and the reviewer comments suggest that the scientific contributions are limited.\n2. The authors claim that AutoOED is the first platform to introduce asynchronous MOBO, but this is not entirely accurate, as other platforms have also implemented asynchronous optimization.\n3. The reviewer comments suggest that the empirical results are not convincing, and the authors' claims are overstated.\n4. The paper lacks a clear theoretical foundation for the Believer-Penalizer strategy, and the authors' explanation is not entirely intuitive.\n\n**Author responses:**\n\nThe authors have addressed many of the reviewer comments, providing additional information and clarifications. However, some concerns remain:\n\n1. The authors have not provided a clear explanation of how the Believer-Penalizer strategy works, and the reviewer comments suggest that the explanation is not entirely intuitive.\n2. The authors have not provided a clear comparison with other platforms, and the reviewer comments suggest that the empirical results are not convincing.\n3. The authors have not addressed the concern that AutoOED only works for 2 or 3 objectives, and the reviewer comments suggest that this is a major limitation.\n\n**Conclusion:**\n\nBased on the detailed analysis, I conclude that the paper has some strengths, but also significant weaknesses. While the authors have made significant contributions to the design and implementation of the AutoOED platform, the scientific contributions are limited, and the empirical results are not convincing. The authors have addressed many of the reviewer comments, but some concerns remain.\n\n**Final Decision:**\n\nReject\n\nThe paper has some strengths, but the weaknesses and concerns raised by the reviewers outweigh the benefits. The authors need to address the limitations and concerns raised by the reviewers and provide a more convincing explanation of the Believer-Penalizer strategy and the empirical results."
    },
    {
      "paper_id": "NudBMY-tzDr",
      "source": "ICLR 2022",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I conclude that the paper should be accepted for publication.\n\nHere's my detailed reasoning:\n\nStrengths:\n\n1. The paper presents a novel and well-motivated approach to interpreting deep learning models for computer vision by generating natural language descriptions of neurons.\n2. The authors provide a clear and concise explanation of their method, MILAN, and its applications.\n3. The paper demonstrates the effectiveness of MILAN in generating accurate and informative descriptions of neurons, with high agreement with human annotations.\n4. The authors provide a thorough evaluation of MILAN's performance across different model architectures, datasets, and tasks.\n5. The paper highlights three interesting applications of MILAN, including analysis, auditing, and editing of learned models.\n\nWeaknesses:\n\n1. Some reviewers raised concerns about the inter-annotator agreement in the MILANNOTATIONS dataset, which is used to train MILAN.\n2. Reviewer 2 suggested that the authors should consider scaling up their methods by leveraging existing large, multimodal datasets like GQA/Visual Genome or visual-language models trained on large paired image-text datasets like CLIP/ALIGN.\n3. Reviewer 4 pointed out that the paper's scope should be clarified, as the title and description suggest a more general method, but the experiments are purely based on images.\n\nAuthor responses:\n\n1. The authors addressed the concerns about inter-annotator agreement by explaining that the lower inter-annotator scores reflect that different annotators often describe different aspects of the masked image regions.\n2. The authors acknowledged the suggestion to scale up their methods and mentioned that they are exploring this direction in future work.\n3. The authors clarified the scope of the paper by changing the title to \"Natural Language Descriptions of Deep Visual Features\" to reflect the finer scope.\n\nOverall, I believe that the paper's strengths outweigh its weaknesses. The authors have presented a novel and effective approach to interpreting deep learning models, with a clear and concise explanation of their method and its applications. While there are some areas for improvement, the authors have addressed the concerns raised by the reviewers and provided a thorough evaluation of their method.\n\nFinal Decision: Accept"
    },
    {
      "paper_id": "M6M8BEmd6dq",
      "source": "ICLR 2022",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel framework for differentially private data synthesis using deep generative models, which is a significant contribution to the field.\n2. The authors provide a clear and well-motivated approach to synthesizing data in a differentially private manner, which is a challenging problem.\n3. The paper has good writing and is well-organized, making it easy to follow.\n4. The authors provide theoretical guarantees of performance, which is a strong aspect of the paper.\n5. The empirical evaluations on multiple datasets show that the approach outperforms other methods at reasonable levels of privacy.\n\n**Weaknesses:**\n\n1. The paper lacks thorough benchmarking, as mentioned by Reviewer 1. The authors should have included more datasets and baselines to compare their approach with.\n2. Reviewer 2 raises concerns about the auxiliary information release and sensitivity calculation, which need to be addressed.\n3. Reviewer 3 points out the need for more related work, justifications for novelty claims, and additional benchmark datasets.\n4. The paper has some minor issues with clarity, as mentioned by Reviewer 3.\n\n**Author Responses:**\n\nThe authors have addressed most of the reviewer comments, including:\n\n1. Adding multiple baselines and datasets to the paper.\n2. Clarifying the optimization procedure and providing more details.\n3. Addressing the concerns about auxiliary information release and sensitivity calculation.\n4. Providing additional evaluation tasks and results.\n\n**Conclusion:**\n\nWhile the paper has some weaknesses, the authors have addressed most of the reviewer comments and provided a clear and well-motivated approach to differentially private data synthesis. The paper has good writing, theoretical guarantees, and empirical evaluations that show the approach outperforms other methods. However, the lack of thorough benchmarking and some minor issues with clarity are concerns that need to be addressed.\n\n**Final Decision:** Accept\n\nThe paper has the potential to make a significant contribution to the field of differentially private data synthesis, and the authors have addressed most of the reviewer comments. With some minor revisions to address the remaining concerns, the paper is suitable for publication in a top-tier conference."
    },
    {
      "paper_id": "L6CKiPH3hI",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\n1. **Novelty and significance**: While the paper proposes a new framework for online knowledge distillation with specialized ensembles, the contributions are only marginally significant or novel. The authors combine existing methods, such as label prior shift and importance sampling, with a new aggregation strategy. However, the novelty is not entirely clear, and the authors do not provide a compelling explanation for why their approach is better than existing methods.\n2. **Experimental results**: The paper presents extensive experimental results, but the comparisons with baseline methods are not always fair. For example, the authors compare their method with PCL on ImageNet, but PCL requires temporal mean networks (TMNs) and multiple peers, which increases the number of parameters and training time. The authors acknowledge this limitation but do not provide a fair comparison.\n3. **Ablation studies**: The authors provide ablation studies to evaluate the effectiveness of each component, but some of the results are not convincing. For example, the authors claim that PC-Softmax is a better option than Softmax, but the results are not clear, and the authors do not provide a detailed explanation.\n4. **Writing and clarity**: The paper is well-written, and the authors provide a clear explanation of their method. However, there are some minor issues with grammar and formatting, which can be easily addressed.\n5. **Reviewer comments**: The reviewers provide valuable feedback, highlighting some of the limitations and concerns with the paper. Reviewer 1 suggests that the authors should conduct more ablations and provide a clearer explanation for their decisions. Reviewer 2 points out that the experimental results are not consistent with the original paper and released code. Reviewer 3 highlights some minor issues with grammar and formatting.\n\nConsidering these observations and concerns, I would recommend **Rejecting** the paper for publication at this stage. While the paper presents some interesting ideas and experimental results, the novelty and significance of the contributions are not entirely clear, and the authors do not provide a compelling explanation for why their approach is better than existing methods. Additionally, some of the experimental results are not convincing, and the authors do not provide a fair comparison with baseline methods.\n\nHowever, I would encourage the authors to revise and resubmit the paper, addressing the concerns and limitations highlighted by the reviewers. With some revisions, the paper has the potential to be a strong contribution to the field of online knowledge distillation.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "-94tJCOo7OM",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author response, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel combination of Monte-Carlo Tree Search (MCTS) and Transformer architecture in offline reinforcement learning, which is an interesting and potentially impactful idea.\n2. The evaluation on SameGame shows that MCTransformer outperforms both Transformer-only and MCTS-only solutions, which provides some evidence for the effectiveness of the proposed method.\n\n**Weaknesses:**\n\n1. **Lack of novelty:** Reviewers 1, 2, and 3 all mention that the paper lacks novelty, as the combination of MCTS and Transformer is not entirely new. AlphaGo/AlphaZero's setting, which uses a neural network to guide MCTS, is mentioned as a similar approach.\n2. **Limited evaluation:** Reviewers 1 and 2 point out that the evaluation is limited to a single domain (SameGame) and does not compare to other well-benchmarked domains like MiniGo or Atari. Reviewer 3 suggests comparing to other methods, such as AlphaZero, and evaluating the proposed method with a standardized test set.\n3. **Poor writing and presentation:** Reviewer 1 mentions that the writing and presentation are unclear, and the exposition of the method could be improved. Reviewer 3 also mentions typos and grammar errors in the paper.\n4. **Lack of reproducibility:** Reviewer 2 mentions that the paper does not provide source code for reproducibility, although Reviewer 3 notes that the method is relatively easy to reproduce.\n\n**Author Response:**\n\nUnfortunately, there is no author response provided, which makes it difficult to address the concerns raised by the reviewers.\n\n**Conclusion:**\n\nBased on the detailed analysis, I conclude that the paper has some interesting ideas, but it lacks novelty, has limited evaluation, and poor writing and presentation. The lack of reproducibility is also a concern. While the paper shows some promise, it requires significant revisions to address the concerns raised by the reviewers.\n\n**Final Decision:** Reject"
    },
    {
      "paper_id": "7fFO4cMBx_9",
      "source": "ICLR 2022",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel generative model, Variational Neural Cellular Automata (VNCA), which is loosely inspired by biological processes of cellular growth and differentiation.\n2. The VNCA is a proper probabilistic generative model, and the authors evaluate it according to best practices.\n3. The paper provides qualitative analysis of the self-organized generation process and shows robustness to early-stage perturbations in the latent space.\n4. The authors have addressed most of the reviewer comments and concerns in their rebuttal, including providing additional experiments and clarifying the architecture and training procedure.\n\n**Weaknesses:**\n\n1. The experimental results are underwhelming, with the VNCA performing worse than state-of-the-art generative models on most datasets.\n2. The paper lacks a clear motivation for the VNCA, and it is not entirely clear what problem it solves compared to existing generative models.\n3. Some reviewers have raised concerns about the novelty and significance of the contributions, with one reviewer suggesting that the VNCA is not significantly different from other deep convolutional networks.\n4. The paper has some minor issues with clarity and notation, which have been addressed in the rebuttal.\n\n**Reviewer comments:**\n\n1. Reviewer 1 is still leaning towards rejection due to underwhelming experimental results.\n2. Reviewer 2 has increased their score but still has concerns about the novelty and significance of the contributions.\n3. Reviewer 3 has raised their score to a full \"accept\" after the rebuttal.\n4. Reviewer 4 is slightly leaning towards rejection due to underwhelming experimental results and lack of clear motivation.\n5. Reviewer 5 has raised their score to a full \"accept\" after the rebuttal.\n6. Reviewer 6 has raised concerns about the novelty and significance of the contributions and the lack of a clear motivation.\n7. Reviewer 7 has raised concerns about the experimental results and the lack of clear motivation.\n\n**Author responses:**\n\n1. The authors have addressed most of the reviewer comments and concerns in their rebuttal.\n2. The authors have provided additional experiments and clarifications on the architecture and training procedure.\n3. The authors have acknowledged some of the weaknesses and limitations of the paper.\n\n**Conclusion:**\n\nBased on the detailed analysis, I conclude that the paper has some strengths, including the novelty of the VNCA and the qualitative analysis of the self-organized generation process. However, the paper also has some significant weaknesses, including underwhelming experimental results, lack of clear motivation, and concerns about novelty and significance. While the authors have addressed most of the reviewer comments and concerns in their rebuttal, some reviewers still have reservations about the paper.\n\n**Final Decision:**\n\nAccept, but with minor revisions to address the remaining concerns and weaknesses.\n\nThe paper has potential, and with some revisions, it can be a strong contribution to the field. However, the current version of the paper is not yet ready for publication in a top-tier conference. The authors should address the remaining concerns and weaknesses, including providing more convincing experimental results, clarifying the motivation and novelty of the VNCA, and addressing the concerns about the architecture and training procedure."
    },
    {
      "paper_id": "3c13LptpIph",
      "source": "ICLR 2023",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper presents a novel approach to offline reinforcement learning (RL) by leveraging online on-policy algorithms, which is a significant contribution.\n2. The theoretical analysis is sound, and the authors provide a clear explanation of the monotonic policy improvement theorem.\n3. The experimental results show that the proposed method, Behavior Proximal Policy Optimization (BPPO), outperforms state-of-the-art offline RL algorithms on the D4RL benchmark.\n\n**Weaknesses:**\n\n1. The paper relies heavily on the assumption that the behavior policy is close to the offline dataset, which may not always be the case in practice.\n2. The authors replace the advantage term in the policy improvement theorem with an estimate of the behavior policy's advantage, which may lead to overestimation and poor performance.\n3. The experimental results show minor improvements over existing algorithms, which may not be significant enough to justify the novelty of the proposed method.\n4. The paper lacks a thorough analysis of the robustness of the proposed method to different hyperparameters and environments.\n\n**Reviewer comments:**\n\n1. Reviewer 1 raises concerns about the clarity of the paper, the soundness of the method, and the lack of experiments to demonstrate the proposed method's robustness.\n2. Reviewer 2 points out that the theoretical results are not new and that the method is similar to existing off-policy TRPO/PPO advances.\n3. Reviewer 3 finds the paper well-written and meaningful but raises questions about the accuracy of the advantage model and the need for K steps to improve the policy.\n4. Reviewer 4 is skeptical about the significance of the results and the simplicity of the proposed method compared to existing baselines.\n5. Reviewer 5 raises concerns about the strong assumption and the replacement of the advantage term.\n\n**Author responses:**\n\n1. The authors address the concerns about the assumption and the replacement of the advantage term, providing a clear explanation of the modifications made to the paper.\n2. The authors provide additional experimental results to demonstrate the robustness of the proposed method.\n3. The authors clarify the significance of the results and the simplicity of the proposed method.\n\n**Conclusion:**\n\nWhile the paper presents a novel approach to offline RL and provides sound theoretical analysis, it has several weaknesses that need to be addressed. The reliance on a strong assumption, the replacement of the advantage term, and the minor improvements over existing algorithms are significant concerns. However, the authors have addressed these concerns in their responses, providing a clear explanation of the modifications made to the paper and additional experimental results to demonstrate the robustness of the proposed method.\n\n**Final Decision:**\n\nAccept\n\nThe paper presents a novel approach to offline RL, and the authors have addressed the concerns raised by the reviewers. While there are still some weaknesses that need to be addressed, the paper has the potential to make a significant contribution to the field of RL."
    },
    {
      "paper_id": "lmumJ2pC0JB",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper provides a sharp convergence analysis of gradient descent for deep linear neural networks with different random initialization methods.\n2. The authors have made significant contributions to the field by extending existing results to general strongly convex and smooth objectives.\n3. The paper is well-written, and the authors have provided clear explanations and discussions of their results.\n4. The authors have addressed several concerns raised by reviewers, including the novelty of their results, the dependence of the minimum width requirement on constants, and the lack of intuitive understanding of the analysis.\n\nWeaknesses:\n\n1. Some reviewers have raised concerns about the novelty of the paper, suggesting that the main results may be a technical extension of existing work.\n2. The paper relies heavily on classical convex optimization techniques and concentration inequalities, which may not be novel or significant contributions.\n3. The authors have not provided a clear explanation of why overparametrization is essential for achieving good convergence rates, and how the width of the network affects the convergence rate.\n4. The paper does not discuss the implications of their results for more general nonlinear neural networks.\n\nBased on the strengths and weaknesses, I believe that the paper has made significant contributions to the field, but the novelty and significance of the results are not entirely clear. The authors have addressed several concerns raised by reviewers, but some concerns remain.\n\nFinal Decision: Accept\n\nI recommend accepting the paper for publication, but with the following conditions:\n\n1. The authors should provide a clear explanation of why overparametrization is essential for achieving good convergence rates, and how the width of the network affects the convergence rate.\n2. The authors should discuss the implications of their results for more general nonlinear neural networks.\n3. The authors should provide a more detailed discussion of the technical barriers that had to be overcome in carrying out the extensions of existing results.\n4. The authors should address any remaining concerns raised by reviewers.\n\nOverall, the paper has made significant contributions to the field, and with some revisions, it can be a high-quality publication."
    },
    {
      "paper_id": "j8s-BRxXST",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper and the reviewer comments, I have the following detailed reasoning:\n\n**Strengths of the paper:**\n\n1. The paper proposes a new contrastive learning objective that addresses the issue of text degeneration in language models.\n2. The idea is intuitive and easy to follow.\n3. The paper provides comprehensive experiments on language modeling and open-domain dialogue generation tasks, showing that the proposed objective yields much less repetitive texts with a higher generation quality than baseline approaches.\n4. The authors have uploaded the code, making it easy to reproduce the results.\n\n**Weaknesses of the paper:**\n\n1. The novelty of the paper is thin, as it builds upon existing work on unlikelihood training.\n2. The experimental setup is limited, with only a few tasks and metrics used to evaluate the proposed objective.\n3. The paper does not provide a clear explanation of why the proposed objective is better than existing approaches, such as unlikelihood training.\n4. Some of the reviewer comments raise concerns about the accuracy of the paper's claims, such as the comparison between the proposed objective and unlikelihood training.\n\n**Reviewer comments:**\n\nAll four reviewers have raised concerns about the paper's novelty, experimental setup, and accuracy of claims. Reviewer 1 and Reviewer 3 have suggested that the paper's contributions are not significant or novel enough to be accepted at a top-tier conference. Reviewer 2 has raised concerns about the experimental setup and the metrics used to evaluate the proposed objective. Reviewer 4 has suggested that the paper's results may not be generalizable to larger models and that the human evaluation does not show statistical significance.\n\n**Author response:**\n\nUnfortunately, there is no author response provided, which makes it difficult to address the reviewer comments and concerns.\n\n**Conclusion:**\n\nBased on the reviewer comments and the analysis above, I conclude that the paper has some strengths, but its weaknesses and limitations outweigh its strengths. The paper's novelty is thin, and the experimental setup is limited. The accuracy of the paper's claims is also a concern, as some reviewer comments raise questions about the comparison between the proposed objective and existing approaches. Therefore, I recommend rejecting the paper for publication at a top-tier conference.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "FLr9RRqbwB-",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper presents an interesting and novel observation about the interaction between batch normalization and bounded activation functions.\n2. The authors provide a clear and logical chain of reasoning to explain the performance improvement of the Swap model.\n3. The paper includes extensive experiments to support the claims, and the author responses address most of the reviewer concerns.\n\n**Weaknesses:**\n\n1. Some reviewer concerns remain unaddressed, such as the potential impact of accelerated training on the performance improvement and the lack of analysis on the behavior of the Convention model with ReLU.\n2. The paper relies heavily on empirical results, and the theoretical foundations are not fully explored.\n3. Some claims, such as the statement about excessive saturation being undesirable, are not well-supported or require clarification.\n4. The paper could benefit from a more comprehensive analysis of the sparsity and saturation metrics, as well as a clearer definition of the center of the function.\n\n**Author responses:**\n\nThe author responses address most of the reviewer concerns, providing additional explanations, clarifications, and experimental results. However, some concerns, such as the potential impact of accelerated training, remain unaddressed.\n\n**Conclusion:**\n\nWhile the paper presents an interesting and novel observation, it has some limitations and weaknesses. The author responses address most of the reviewer concerns, but some concerns remain unaddressed. Considering the strengths and weaknesses, I believe that the paper has the potential to be published in a top-tier conference, but it requires further refinement and clarification.\n\n**Final Decision:** Accept"
    },
    {
      "paper_id": "0OlEBibFa_g",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper and the reviewer comments, I have the following detailed reasoning:\n\n**Strengths of the paper:**\n\n1. The idea of using graph structures and topological properties to detect out-of-distribution (OOD) data is novel and interesting.\n2. The paper demonstrates competitive performance on the LSUN dataset, with AUROC scores of 97.95% and 98.79% for far-OOD and near-OOD detection, respectively.\n3. The authors provide a clear and concise abstract and introduction, which sets the stage for the rest of the paper.\n\n**Weaknesses of the paper:**\n\n1. The paper lacks a clear and rigorous definition of the terms \"Common sense\" and \"computational models that mimic child cognition,\" which are used to motivate the proposed method.\n2. The authors do not provide a detailed description of the feature extraction procedure, including an example that guides the reader through image->object detection->graph creation steps using actual data.\n3. The paper relies on a pre-trained object detection network that contains sufficient semantic information for the in-distribution data, which may not be the case for all datasets (e.g., medical images).\n4. The experimental section is limited, and the authors do not compare their method to other state-of-the-art methods for OOD detection.\n5. The paper lacks ablation studies, such as how the graph affects the results, and the authors do not provide an analysis of how the object detector's accuracy impacts the current model.\n6. The paper has several grammatical mistakes, which make it difficult to understand.\n\n**Reviewer comments:**\n\nAll reviewers agree that the paper has some strengths, but also several weaknesses. Reviewer 1 suggests that the authors provide a more detailed description of the feature extraction procedure and compare their method to other low-dimensional projection techniques. Reviewer 2 recommends a strong reject due to the paper's poor writing, lack of clear notation, and failure to compare to existing state-of-the-art methods. Reviewer 3 suggests that the idea is not novel enough and the experiments are not persuasive. Reviewer 4 provides a more balanced review, highlighting both the strengths and weaknesses of the paper.\n\n**Author response:**\n\nUnfortunately, there is no author response provided, which makes it difficult to address the reviewers' concerns and provide a more detailed explanation of the paper's contributions.\n\n**Conclusion:**\n\nBased on the reviewer comments and the paper's weaknesses, I recommend **Reject**. While the paper has some interesting ideas and competitive performance on the LSUN dataset, it lacks a clear and rigorous definition of key terms, a detailed description of the feature extraction procedure, and a comprehensive experimental evaluation. Additionally, the paper relies on a pre-trained object detection network that may not be suitable for all datasets, and the authors do not provide an analysis of how the object detector's accuracy impacts the current model. With some revisions to address these concerns, the paper may be more suitable for publication in a top-tier conference.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "-SBZ8c356Oc",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\n1. **Theoretical contribution**: The paper claims to derive a new upper bound of the robust risk, which is theoretically motivated. However, several reviewers have pointed out that the bound is not tighter than the existing bound in TRADES for binary classification problems, and the extension to multi-classification problems is not well-motivated. The authors have acknowledged these concerns and revised the manuscript to focus on multi-classification problems.\n2. **Experimental results**: The paper presents extensive experimental results, which show that the proposed method, ARoW, outperforms existing methods in terms of robust accuracy. However, some reviewers have pointed out that the improvements are marginal, and the results for the case of extra data are not convincing. The authors have provided additional results to address these concerns.\n3. **Implementation and fairness**: The authors have highlighted the ease of implementation of ARoW compared to HAT and its improved fairness on class-wise robustness.\n4. **Reviewer comments**: Several reviewers have raised concerns about the clarity and rigor of the theoretical part, particularly the definition of $z(x)$ and the derivation of the upper bound. The authors have provided a revised definition of $z(x)$ and clarified the meaning of the upper bound.\n\nConsidering these points, I believe that the paper has made significant progress in addressing the concerns raised by the reviewers. However, I still have some reservations about the theoretical contribution and the experimental results.\n\n**Detailed reasoning**:\n\n* The paper's theoretical contribution is not as strong as initially claimed, and the extension to multi-classification problems is not well-motivated.\n* The experimental results show that ARoW outperforms existing methods, but the improvements are marginal, and the results for the case of extra data are not convincing.\n* The authors have addressed some of the concerns raised by the reviewers, but some issues remain, such as the clarity and rigor of the theoretical part.\n\n**Final Decision**: Accept\n\nI recommend accepting the paper for publication, subject to minor revisions to address the remaining concerns. The authors have made significant progress in addressing the reviewers' comments, and the paper presents interesting and relevant results in the area of adversarial robustness. However, the paper's theoretical contribution and experimental results could be further strengthened to make it more competitive in the field."
    },
    {
      "paper_id": "FLr9RRqbwB-",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper presents an interesting and novel observation about the interaction between batch normalization and bounded activation functions.\n2. The authors provide a clear and logical chain of reasoning to explain the performance improvement of the Swap model.\n3. The paper includes extensive experiments to support the claims, and the author responses address many of the reviewer concerns.\n\n**Weaknesses:**\n\n1. Some of the reviewer concerns remain unaddressed, such as the lack of clarity on the definition of \"center of the function\" and the potential for gradient vanishing problems with Tanh.\n2. The paper relies heavily on empirical results, and the theoretical justification for the observed phenomena is limited.\n3. The analysis is limited to a specific set of architectures and activation functions, which may not generalize to other cases.\n4. The paper does not provide a clear explanation for the reversed behavior of the Swap model with ReLU.\n\n**Reviewer Comments:**\n\n1. Reviewer 1 raises concerns about the lack of quantitative information and the potential for biased results.\n2. Reviewer 2 highlights the need for more convincing arguments connecting the observation to the conclusions.\n3. Reviewer 3 suggests that the analysis is less comprehensive and that the conclusions may be less practical.\n4. Reviewer 4 raises concerns about the potential for accelerated training and the lack of analysis on the effect of weight decay.\n5. Reviewer 5 highlights the need for more rigorous clarification of some claims and the potential for contradictory results.\n\n**Author Responses:**\n\n1. The authors address many of the reviewer concerns, providing additional information and clarification.\n2. However, some concerns remain unaddressed, such as the definition of \"center of the function\" and the potential for gradient vanishing problems.\n\n**Conclusion:**\n\nWhile the paper presents an interesting and novel observation, the reviewer concerns and author responses highlight several limitations and areas for improvement. The paper relies heavily on empirical results, and the theoretical justification for the observed phenomena is limited. Additionally, the analysis is limited to a specific set of architectures and activation functions, which may not generalize to other cases.\n\nConsidering these factors, I recommend **Rejecting** the paper for publication in its current form. However, I encourage the authors to address the remaining concerns and limitations, providing a more comprehensive and theoretically justified explanation for the observed phenomena.\n\n**Recommendations for Revision:**\n\n1. Provide a clear and rigorous definition of \"center of the function\" and its implications.\n2. Address the potential for gradient vanishing problems with Tanh and provide a more comprehensive analysis of the effect of weight decay.\n3. Provide a more theoretical justification for the observed phenomena, including a discussion of the underlying mechanisms and potential generalizations to other cases.\n4. Include additional experiments to support the claims and provide a more comprehensive analysis of the limitations and potential biases.\n\nBy addressing these concerns and limitations, the authors can strengthen the paper and provide a more comprehensive and theoretically justified explanation for the observed phenomena."
    },
    {
      "paper_id": "h9O0wsmL-cT",
      "source": "ICLR 2023",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following observations and concerns:\n\n**Strengths:**\n\n1. The paper proposes a novel label differential privacy mechanism, \"Randomized Response on Bins\" (RR-on-Bins), which is optimal under a given regression loss function.\n2. The authors provide a thorough experimental evaluation on several datasets, demonstrating the efficacy of their algorithm.\n3. The paper is well-written, and the authors have addressed most of the reviewer comments and concerns.\n\n**Weaknesses:**\n\n1. Some reviewers have raised concerns about the distinction between regression and classification tasks, and whether the proposed mechanism is optimal for regression tasks.\n2. Reviewer 3 has pointed out that the paper does not compare against other label-DP methods, such as [1] by Ghazi et al.\n3. Reviewer 5 has suggested that the paper should consider the second term in Equation (1), which represents the Bayes optimal error, to improve the proposed mechanism.\n4. Reviewer 6 has pointed out that the paper maps the response to finite possible values, which may not be suitable for regression tasks.\n\n**Author Responses:**\n\nThe authors have addressed most of the reviewer comments and concerns, providing additional explanations and clarifications. However, some concerns remain:\n\n1. The authors have not fully addressed the distinction between regression and classification tasks, and whether the proposed mechanism is optimal for regression tasks.\n2. The authors have not compared their method against other label-DP methods, such as [1] by Ghazi et al.\n3. The authors have not fully explored the suggestion by Reviewer 5 to consider the second term in Equation (1).\n\n**Conclusion:**\n\nBased on the strengths and weaknesses of the paper, as well as the author responses, I believe that the paper has the potential to be accepted for publication. However, I recommend that the authors make some revisions to address the remaining concerns:\n\n1. Provide a more detailed explanation of the distinction between regression and classification tasks, and why the proposed mechanism is optimal for regression tasks.\n2. Compare the proposed method against other label-DP methods, such as [1] by Ghazi et al.\n3. Explore the suggestion by Reviewer 5 to consider the second term in Equation (1) and provide a more comprehensive analysis.\n\n**Final Decision:** Accept"
    },
    {
      "paper_id": "u6KhE9fapjX",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel approach to collaborative adversarial training, which is an interesting and timely topic in the field of adversarial robustness.\n2. The authors provide extensive experimental results on CIFAR-10 and CIFAR-100 datasets, which demonstrate the effectiveness of their proposed method.\n3. The paper is well-written and easy to follow, making it accessible to a broad audience.\n\n**Weaknesses:**\n\n1. The idea of collaborative adversarial training is not entirely novel, as mentioned by Reviewer 1 and Reviewer 2. There are existing methods that combine multiple defenses or use ensemble techniques to improve robustness.\n2. The paper lacks a theoretical analysis of the proposed method, which makes it difficult to understand why the collaborative approach improves robustness.\n3. The experimental results are limited to small-scale datasets (CIFAR-10 and CIFAR-100) and a single network architecture. Larger datasets and more architectures should be considered to support the effectiveness of the proposed method.\n4. The paper does not provide a clear explanation of why the proposed method improves performance, and how the adversarial training methods are different in the first place.\n5. The authors do not provide a comparison with more recent and stronger baselines, such as Adversarial Weight Perturbation (AWP).\n\n**Reviewer Comments:**\n\n1. Reviewer 1 highlights the lack of theoretical analysis and the need for more detailed experimental analysis and baselines for comparison.\n2. Reviewer 2 criticizes the lack of novelty in the proposed method and the absence of a theoretical analysis.\n3. Reviewer 3 suggests comparing the proposed method with data augmentation approaches and evaluating it on larger datasets and more architectures.\n4. Reviewer 4 highlights the need for more ablations, such as involving more attackers in collaborative training and comparing the proposed method with AWP.\n\n**Author Response:**\n\nUnfortunately, there is no author response provided, which makes it difficult to address the concerns raised by the reviewers.\n\n**Conclusion:**\n\nBased on the strengths and weaknesses of the paper, as well as the reviewer comments, I conclude that the paper has some interesting ideas and experimental results, but it lacks a clear theoretical analysis and a comprehensive comparison with existing methods. The paper also has some limitations in terms of the scope of the experiments and the lack of novelty in the proposed approach.\n\n**Final Decision:**\n\nAccept with Major Revisions\n\nThe paper has potential, but it requires significant revisions to address the concerns raised by the reviewers. The authors should provide a clear theoretical analysis of the proposed method, conduct more comprehensive experiments, and compare their method with more recent and stronger baselines. Additionally, they should address the limitations of the paper and provide a clear explanation of why the proposed method improves performance."
    },
    {
      "paper_id": "9D5FH6LFbRu",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper presents a novel and interesting framework for supervised learning, which has the potential to improve our understanding of generalization in the over-parameterized regime.\n2. The authors provide a clear and concise abstract, and the paper is well-written, with a good balance of theoretical and experimental results.\n3. The paper has a high level of technical novelty and significance, as it challenges the classic assumption of data coming from a single function and proposes a new framework for scalable training objectives.\n4. The authors have addressed many of the concerns raised by the reviewers, including scalability, experimental evaluation, and clarity of the paper.\n\n**Weaknesses:**\n\n1. The paper still has some issues with clarity and presentation, particularly in the introduction and related work sections.\n2. Some of the reviewer comments, such as those from Reviewer 1, highlight concerns about the scalability and theoretical foundations of the proposed framework.\n3. The paper could benefit from more experimental evaluation, particularly in the unsupervised learning setting.\n4. While the authors have addressed some of the concerns raised by the reviewers, there are still some open questions and areas for future work.\n\n**Author Response:**\n\nThe author response is thorough and addresses many of the concerns raised by the reviewers. The authors provide additional experimental results, clarify the scalability of the proposed framework, and address concerns about the theoretical foundations of the paper.\n\n**Conclusion:**\n\nBased on the detailed analysis, I believe that the paper has made significant progress in addressing the concerns raised by the reviewers. The authors have provided a clear and concise paper, with a good balance of theoretical and experimental results. While there are still some open questions and areas for future work, I believe that the paper has the potential to make a significant contribution to the field of machine learning.\n\n**Final Decision:** Accept"
    },
    {
      "paper_id": "HlRfoQDDj-V",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper and the reviewer comments, I have the following detailed reasoning:\n\n**Strengths of the paper:**\n\n1. The paper tackles an important problem in machine learning, which is the trade-off between model performance and validation set size.\n2. The proposed solution, Proximal Validation Protocol (PVP), is novel and appears to be effective in addressing this problem.\n3. The paper provides extensive empirical findings, demonstrating the efficacy of PVP on three different data modalities (images, text, and tabular data).\n\n**Weaknesses of the paper:**\n\n1. The experiments are unclear and lacking in thoroughness, as pointed out by Reviewer 1. Specifically, the paper only evaluates the performance of PVP on a fixed model, without demonstrating its ability to select between different models or hyperparameters.\n2. The paper lacks theoretical justification for the proposed method, which is a major concern raised by Reviewer 4.\n3. The empirical evaluation is limited to small datasets, which may not fully support the claims made in the paper (as pointed out by Reviewer 2).\n4. The paper does not provide a clear explanation of how to decide the size of the proximal validation set, which is an important hyperparameter (as pointed out by Reviewer 3).\n\n**Reviewer comments:**\n\nAll reviewers agree that the paper tackles an important problem and proposes a novel solution. However, they also raise several concerns about the clarity, thoroughness, and theoretical justification of the paper.\n\n**Author response:**\n\nUnfortunately, there is no author response provided, which makes it difficult to address the concerns raised by the reviewers.\n\n**Conclusion:**\n\nBased on the detailed analysis above, I conclude that the paper has some strengths, but also several weaknesses that need to be addressed. While the proposed solution is novel and appears to be effective, the paper lacks thorough empirical evaluation, theoretical justification, and clear explanations of important hyperparameters. Therefore, I recommend **Reject**.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "KNSRDB-clPX",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author response, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper addresses an important problem in protein-protein interaction (PPI) prediction, which is a critical task in understanding cellular behavior and functionality.\n2. The use of pre-trained structure embeddings from OmegaFold is a novel approach that leverages structural information, which is not typically considered in PPI prediction.\n3. The paper provides a clear and well-motivated approach to incorporating structural embeddings into a graph neural network (GNN) for PPI prediction.\n\n**Weaknesses:**\n\n1. Limited novelty and contribution: Reviewers 1, 2, and 3 all mention that the paper's contributions are limited, and the approach is not particularly novel or significant.\n2. Poor baseline choices: Reviewer 4 points out that the baseline for comparison is arbitrarily weak and not the previous state of the art.\n3. Unclear model design: Reviewer 4 also questions the advantage of using both structural embeddings and GNN aggregation, as the results do not support this claim.\n4. Lack of comparison to other methods: Reviewer 3 mentions that the paper only compares to GraphSAGE and GAT, which may not be the state-of-the-art methods for PPI prediction.\n5. Limited empirical results: Reviewer 3 also points out that the empirical results only show marginal improvements and do not have confidence intervals.\n\n**Author Response:**\n\nUnfortunately, there is no author response provided, which makes it difficult to address the reviewers' concerns and provide a clear justification for the paper's contributions.\n\n**Conclusion:**\n\nBased on the reviewer comments and the analysis above, I believe that the paper has some strengths, but its limitations and weaknesses outweigh its contributions. The paper's novelty and significance are limited, and the baseline choices are poor. Additionally, the model design is unclear, and the empirical results are limited.\n\n**Final Decision: Reject**\n\nThe paper's limitations and weaknesses, combined with the lack of a clear author response, make it difficult to accept the paper for publication in a top-tier conference like ICLR. While the paper addresses an important problem, its contributions are not significant enough to warrant publication in a top-tier conference."
    },
    {
      "paper_id": "QN_VgTeOYGl",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper addresses an important and novel problem in federated learning, specifically data leakage in tabular data.\n2. The authors propose a simple yet effective method, TabLeak, to tackle this problem, which is easy to plug into existing approaches.\n3. The experimental evaluation is thorough and demonstrates the effectiveness of TabLeak on four popular tabular datasets.\n4. The authors provide a clear and well-written paper, with a good balance of technical and non-technical content.\n\n**Weaknesses:**\n\n1. The paper's novelty and significance are questioned by Reviewer 2, who argues that the contributions are only marginally significant or novel.\n2. Reviewer 1 points out that the solutions to tackle the challenges of tabular data are quite standard, which may limit the paper's impact.\n3. Reviewer 3 raises concerns about the specificity of the problem and the justification for the use of pooling.\n4. The paper's writing style and grammar are criticized by Reviewer 1, which may affect the paper's overall quality.\n\n**Author Responses:**\n\nThe authors have provided detailed responses to the reviewer comments, addressing many of the concerns raised. They have also provided additional experiments and analysis to support their claims.\n\n**Conclusion:**\n\nBased on the strengths and weaknesses of the paper, as well as the author responses, I believe that the paper has the potential to be a valuable contribution to the field of federated learning. However, I also agree with Reviewer 2 that the novelty and significance of the work may be limited. Therefore, I recommend that the paper be accepted for publication, but with the understanding that the authors should be encouraged to further develop and refine their work to address the concerns raised by the reviewers.\n\n**Final Decision:** Accept"
    },
    {
      "paper_id": "pRCMXcfdihq",
      "source": "ICLR 2023",
      "true_decision": "Accept",
      "prediction": "Accept",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel approach for protein sequence and structure co-design, which is a significant contribution to the field.\n2. The method is well-motivated and the modeling way is reasonable and solid.\n3. The results show strong improvements over previous works on different tasks.\n4. The authors have addressed most of the concerns raised by the reviewers and have provided clear and detailed responses.\n\n**Weaknesses:**\n\n1. Some of the claims in the paper are not well-supported or require small changes to be made correct.\n2. The paper lacks specific hyperparameter and training details, which makes it difficult to reproduce the results.\n3. The authors have not released the code and trained models, which is a concern for reproducibility.\n4. Some of the reviewer comments suggest that the novelty of the work is not as significant as claimed by the authors.\n\n**Concerns:**\n\n1. The authors have made some claims that are not accurate or are misleading, such as the claim that their method is the first to directly target protein sequence and structure co-design.\n2. The paper relies heavily on the use of context features, which may not be applicable to all protein design tasks.\n3. The authors have not provided a clear explanation of how their method can be adapted to handle context-free protein design.\n\n**Author Responses:**\n\n1. The authors have addressed most of the concerns raised by the reviewers and have provided clear and detailed responses.\n2. The authors have revised the paper to make it more clear and accurate.\n3. The authors have promised to release the code and trained models upon acceptance of the paper.\n\n**Conclusion:**\n\nBased on the strengths, weaknesses, and concerns, I believe that the paper has made significant contributions to the field of protein sequence and structure co-design. However, there are still some concerns that need to be addressed, such as the lack of specific hyperparameter and training details, the reliance on context features, and the accuracy of some claims. The authors have addressed most of the concerns raised by the reviewers and have provided clear and detailed responses.\n\n**Final Decision:** Accept\n\nThe paper has the potential to make a significant impact in the field of protein sequence and structure co-design, and the authors have demonstrated a willingness to address the concerns raised by the reviewers. However, the authors should be required to provide more specific hyperparameter and training details, release the code and trained models, and provide a clear explanation of how their method can be adapted to handle context-free protein design."
    },
    {
      "paper_id": "Gkbxt7ThQxU",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses (or lack thereof), I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper tackles a challenging problem in reinforcement learning, which is maintaining diverse playing styles in self-play.\n2. The proposed bi-objective optimization model is an interesting and novel approach to address this problem.\n3. The experiments in Pong and Justice Online show promising results, with the proposed method learning a well-generalized policy and producing high-level policies with various playing styles.\n4. The paper is well-written and easy to follow, with a clear and concise abstract.\n\n**Weaknesses:**\n\n1. Reviewer 1 points out that the paper misses an important part of the literature, specifically the work by Lanctot et al. (2017), which describes a general framework for multiagent RL that includes self-play algorithms like Iterated-Best Response, Fictitious Play, and Double Oracle.\n2. Reviewer 1 also notes that the experimental design is problematic, as it gives an advantage to EMOGI and BiO due to the sampling of opponents from the pool of agents.\n3. Reviewer 2 points out that reducing \"playing style\" to a single scalar is a huge simplification and potential limitation.\n4. Reviewer 3 notes that the paper lacks baselines from quality-diversity algorithms, such as MAP-Elites, and relatively few evaluation domains for more rigorous comparison.\n5. Reviewer 3 also points out that the style results show some diversity, but in a relatively narrow sense, and that the lack of a breadth of empirical results makes it hard to see the results as robust to a wide variety of competitive RL tasks.\n\n**Correctness, Technical Novelty, and Empirical Novelty:**\n\n1. Reviewer 1 gives a correctness score of 2, indicating that several of the paper's claims are incorrect or not well-supported.\n2. Reviewer 2 gives a correctness score of 4, indicating that all of the claims and statements are well-supported and correct.\n3. Reviewer 3 gives a correctness score of 3, indicating that some of the paper's claims have minor issues.\n4. Reviewer 1 gives a technical novelty score of 2, indicating that the contributions are only marginally significant or novel.\n5. Reviewer 2 gives a technical novelty score of 3, indicating that the contributions are significant and somewhat new.\n6. Reviewer 3 gives a technical novelty score of 2, indicating that the contributions are only marginally significant or novel.\n7. Reviewer 1 gives an empirical novelty score of 2, indicating that the contributions are only marginally significant or novel.\n8. Reviewer 2 gives an empirical novelty score of 3, indicating that the contributions are significant and somewhat new.\n9. Reviewer 3 gives an empirical novelty score of 2, indicating that the contributions are only marginally significant or novel.\n\n**Conclusion:**\n\nBased on the reviewer comments and the analysis above, I conclude that the paper has some strengths, but also several weaknesses that need to be addressed. The paper tackles a challenging problem, proposes a novel approach, and shows promising results. However, the paper misses important parts of the literature, has a problematic experimental design, and lacks baselines from quality-diversity algorithms. Additionally, the style results show some diversity, but in a relatively narrow sense, and the lack of a breadth of empirical results makes it hard to see the results as robust to a wide variety of competitive RL tasks.\n\n**Final Decision:**\n\nAccept, but with major revisions.\n\nThe paper has potential, but it needs significant revisions to address the weaknesses mentioned above. The authors should:\n\n1. Include a discussion of the work by Lanctot et al. (2017) and its relevance to the proposed method.\n2. Revise the experimental design to avoid giving an advantage to EMOGI and BiO.\n3. Address the simplification of \"playing style\" to a single scalar and discuss its limitations.\n4. Include baselines from quality-diversity algorithms, such as MAP-Elites.\n5. Conduct more rigorous comparisons with a wider range of evaluation domains.\n6. Provide more details on the style results, including plots for more agents and a discussion of the diversity of playing styles.\n\nWith these revisions, the paper has the potential to make a significant contribution to the field of reinforcement learning."
    },
    {
      "paper_id": "kL67fyKb6A",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper addresses a relevant and challenging problem in machine learning, namely online adaptation to label-shift in the presence of conditional-shift.\n2. The authors propose several heuristics to improve the performance of online adaptation methods in such scenarios.\n3. The paper provides empirical evidence to support the effectiveness of the proposed heuristics on various datasets.\n\n**Weaknesses:**\n\n1. The paper lacks a systematic or principled approach to the types of distribution shifts considered. The authors focus on a specific type of shift, but do not provide a comprehensive analysis of other types of shifts.\n2. The empirical investigation is limited, and the authors do not provide a thorough comparison with alternative methods, such as offline domain adaptation methods or domain generalization methods.\n3. Some key definitions and explanations are lacking in the paper, making it difficult to understand certain sections.\n4. The authors' heuristics are not well-motivated, and the paper lacks theoretical justification for the proposed methods.\n5. The paper has some minor issues with clarity and notation, which can make it difficult to follow.\n\n**Author Responses:**\n\nThe authors have addressed some of the reviewers' concerns, but not all of them. They have provided additional details on the estimation of p, the relevance of the Bayesian connection, and the soundness of the proposed heuristics. However, they have not provided a comprehensive response to all the reviewers' comments.\n\n**Conclusion:**\n\nBased on the strengths and weaknesses of the paper, as well as the author responses, I conclude that the paper has some potential but requires significant revisions to address the concerns raised by the reviewers. The paper's contributions are not entirely novel, and the empirical investigation is limited. However, the paper does address a relevant problem, and the proposed heuristics show some promise.\n\n**Final Decision:** Accept with Major Revisions\n\nThe paper should be accepted for publication, but the authors must address the major concerns raised by the reviewers, including:\n\n1. Providing a more comprehensive analysis of the types of distribution shifts considered.\n2. Conducting a more thorough comparison with alternative methods.\n3. Clarifying key definitions and explanations.\n4. Providing theoretical justification for the proposed methods.\n5. Addressing minor issues with clarity and notation.\n\nThe authors should revise the paper to address these concerns and provide a more comprehensive and well-motivated contribution to the field."
    },
    {
      "paper_id": "jZfksUBb3Zz",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the research paper, reviewer comments, and author response, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes an interesting idea of using binary labels as an auxiliary task to improve image classification performance.\n2. The results show small improvements over baseline methods using standard one-hot encoding, especially for classification in special domains.\n3. The approach is simple and effective, and the use of random binary partitions can create useful related tasks for the neural network to train on.\n\n**Weaknesses:**\n\n1. The technical contribution of the paper seems limited, and the main idea is to use binary labels as an auxiliary task during training.\n2. The multi-task learning architecture is basic, with one independent branch for each task.\n3. The paper lacks clear explanations of how binary labels improve performance and what problem they solve.\n4. The experimental results are insufficient to show the effectiveness of the algorithm, and the baseline algorithm was set to those with too low performance.\n5. The paper does not clearly explain how binary labels are generated in the experiment section.\n6. The paper lacks analysis of the weighting between the two tasks and its robustness.\n7. The proposed approach seems to be limited to multiclass image classification and does not generalize to multilabel image classification.\n8. The paper does not evaluate on large benchmarks like ImageNet.\n\n**Reviewer Comments:**\n\n1. Reviewer 1 highlights the clarity issues, experimental weaknesses, and lack of intuition or analysis to shed light on when the proposed approach helps.\n2. Reviewer 2 criticizes the paper's notations, calculation errors, and lack of insight or analysis in the proposed algorithm.\n3. Reviewer 3 praises the simplicity and effectiveness of the approach but notes that the contribution might not be significant enough due to small empirical improvements.\n4. Reviewer 4 highlights the limited technical contribution, lack of clear explanation of how binary labels improve performance, and insufficient experimental results.\n\n**Author Response:**\n\nUnfortunately, there is no author response provided, which makes it difficult to address the reviewers' concerns and provide a clear explanation of the paper's contributions.\n\n**Conclusion:**\n\nBased on the detailed analysis, I conclude that the paper has some interesting ideas, but its technical contribution is limited, and the experimental results are insufficient to show the effectiveness of the algorithm. The paper lacks clear explanations of how binary labels improve performance and what problem they solve. Additionally, the paper does not clearly explain how binary labels are generated in the experiment section, and the analysis of the weighting between the two tasks is lacking.\n\nTherefore, I recommend **Rejecting** the paper for publication at a top-tier conference.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "-4DiyBMgv9m",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper and the reviewer comments, I have the following observations:\n\n1. The paper presents a novel contribution to the field of permuted linear regression, specifically in identifying the phase transition thresholds via message passing.\n2. However, the paper has several issues with clarity, quality, and reproducibility. The writing is often dense and difficult to follow, with many typos and grammatical errors. The notation and definitions are not always clear, and the authors often refer to external sources without providing sufficient context.\n3. The paper relies heavily on prior work, and some of the results seem to be corollaries of established theorems. The authors' claims about the novelty and significance of their contributions are not entirely supported by the evidence.\n4. The numerical experiments and results are not well-presented, and the authors' claims about the alignment of empirical and theoretical results are not convincing.\n5. The paper has several minor issues, such as the use of vague terminology, unclear notation, and incomplete explanations.\n\nConsidering these observations, I believe that the paper requires significant revisions to address the issues mentioned above. The authors need to improve the clarity and quality of the writing, provide more context and explanations for the notation and definitions, and ensure that the claims about novelty and significance are supported by the evidence.\n\nBased on the reviewer comments and my analysis, I conclude that the paper is not yet ready for publication in its current form. Therefore, I recommend that the authors revise the paper thoroughly and resubmit it for consideration.\n\nFinal Decision: Reject"
    },
    {
      "paper_id": "mNk7mgWZcJa",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper and the reviewer comments, I have the following detailed reasoning:\n\n**Strengths of the paper:**\n\n1. The paper addresses an important problem in the field of machine learning, specifically privacy-preserving representation learning in the context of Machine Learning as a Service (MLaaS).\n2. The authors propose a novel approach called \"Scrunch\" that splits a neural network into two parts, with the client applying raw data through the first part and sending the encoded data to the server for final inference.\n3. The paper presents results on two models (LeNet-5 and VGG-16) and two datasets (MNIST and CelebA), which demonstrates the feasibility of the proposed approach.\n\n**Weaknesses of the paper:**\n\n1. The reviewer comments highlight several technical flaws and concerns with the paper, including:\n\t* The proposed approach is flawed due to the server's ability to recreate a \"surrogate\" encoder, which compromises the privacy of the client's data.\n\t* The threat model is incomplete, and the server can easily turn off the center loss to zero and back propagate only the cross-entropy loss.\n\t* The experimental evaluation is simplistic, and the results are unconvincing.\n\t* The paper lacks a clear security model, and the use of middle features of the neural network is still risky for information leakage.\n2. The paper has several grammatical errors and ambiguous statements, which affect the clarity and quality of the paper.\n3. The novelty of the work is somewhat limited, and the core idea is similar to split learning, which has not been mentioned in the paper.\n\n**Author Response:**\n\nUnfortunately, there is no author response provided, which makes it difficult to address the reviewer comments and concerns.\n\n**Final Decision:**\n\nBased on the detailed analysis, I conclude that this paper should be **Rejected** for publication at a top-tier conference like ICLR. The paper has several technical flaws, concerns, and limitations that need to be addressed before it can be considered for publication. The reviewer comments highlight several issues with the paper, including the flawed approach, incomplete threat model, simplistic experimental evaluation, and lack of clear security model. While the paper addresses an important problem, the current version is not ready for publication in a top-tier conference."
    },
    {
      "paper_id": "IQM-3_Tzldw",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses (or lack thereof), I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper identifies a novel problem in federated learning, namely \"period drift,\" which is a significant contribution.\n2. The authors propose a learning-based parameterized aggregator, FedPA, to address this issue, which is a novel approach.\n3. The paper presents experimental results showing the effectiveness of FedPA in various settings.\n\n**Weaknesses:**\n\n1. Reviewer 1 and Reviewer 3 raise concerns about the lack of theoretical justification for the proposed method and the limited novelty of the contributions.\n2. Reviewer 1 and Reviewer 2 suggest that the paper lacks an in-depth discussion on why meta-learning frameworks are particularly suited for the period drift problem.\n3. Reviewer 3 and Reviewer 4 point out that the proposed method seems to be ad-hoc and that there are easier approaches to use the proxy data.\n4. Reviewer 1 and Reviewer 3 raise concerns about the experimental performance, with Reviewer 3 noting that the accuracy on FEMNIST seems to be lower than expected.\n5. Reviewer 4 suggests that the overhead on the server should be quantified and that the method may not be applicable at scale.\n\n**Author Response:**\n\nUnfortunately, there is no author response provided, which makes it difficult to address the concerns raised by the reviewers.\n\n**Conclusion:**\n\nBased on the detailed analysis, I conclude that the paper has some significant contributions, but it also has several weaknesses that need to be addressed. The lack of theoretical justification, limited novelty, and ad-hoc nature of the proposed method are major concerns. Additionally, the experimental performance and overhead on the server are not satisfactory.\n\nGiven the concerns raised by the reviewers and the lack of author response, I recommend **Rejecting** the paper for publication at this time. However, I encourage the authors to address the concerns raised by the reviewers and resubmit the paper for further consideration.\n\n**Final Decision:** Reject"
    },
    {
      "paper_id": "Jdj0fZhswJC",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Reject",
      "correct": true,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\nStrengths:\n\n1. The paper addresses an important and challenging problem in the field of learning in games, which is the convergence to good equilibria.\n2. The authors provide a comprehensive analysis of the average-case performance of no-regret learning dynamics, including q-replicator dynamics, in a class of games.\n3. The paper combines tools from machine learning, game theory, and dynamical systems, which is a unique and valuable contribution.\n4. The authors provide a clear and well-written paper, with a well-structured introduction, methodology, and results.\n\nWeaknesses:\n\n1. The paper's main contribution is the analysis of the average-case performance of no-regret learning dynamics in a specific class of games, which is a relatively restricted setting.\n2. The results are partial and do not provide a complete treatment of the problem, as mentioned by Reviewer 3.\n3. The paper does not provide a clear comparison with prior work, such as PP16, which is a significant omission, as mentioned by Reviewer 2.\n4. The paper's significance and novelty are questionable, as mentioned by Reviewer 2 and Reviewer 3.\n\nAuthor responses:\n\n1. The authors have addressed the concerns raised by Reviewer 1, Reviewer 2, and Reviewer 3, including clarifying the abstract, improving the formatting of citations, and providing additional discussion on the comparison with PP16.\n2. The authors have also provided additional information on the scope of the paper and the challenges of extending the results to more general games.\n\nBased on the detailed analysis, I conclude that the paper has some strengths, but also significant weaknesses. While the authors have addressed some of the concerns raised by the reviewers, the paper's main contribution is still limited to a specific class of games, and the results are partial.\n\nFinal Decision: Reject\n\nThe paper's limitations and weaknesses outweigh its strengths, and it does not meet the high standards of a top-tier conference. However, I encourage the authors to revise and resubmit the paper, addressing the concerns raised by the reviewers and providing a more complete treatment of the problem."
    },
    {
      "paper_id": "dyifcA9UuRo",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper proposes a novel neural probabilistic logic programming language, DeepSeaProbLog, which supports both discrete and continuous random variables.\n2. The authors provide a clear and concise explanation of the language and its semantics.\n3. The paper introduces a new task, MNIST subtraction, which requires algorithms to simultaneously learn the bounding boxes of MNIST digits and compute their subtracted values.\n4. The authors provide an implementation of DeepSeaProbLog that supports inference and gradient-based learning.\n5. The paper includes an experimental evaluation of the approach, which shows promising results.\n\n**Weaknesses:**\n\n1. Some reviewers have raised concerns about the incrementality of the contribution, suggesting that it builds upon existing work in the field.\n2. Reviewer 2 and Reviewer 3 have suggested that the empirical evaluation is not extensive and that more benchmarks and applications should be included.\n3. Reviewer 4 has pointed out that the paper relies on approximations to ensure efficiency, which may limit its scalability.\n4. Reviewer 6 has raised concerns about the clarity of the paper, suggesting that the authors have not provided enough details about how they handle discrete random variables.\n5. Reviewer 7 has suggested that the paper feels incremental and that the example used is contrived.\n\n**Author Responses:**\n\nThe authors have provided detailed responses to the reviewer comments, addressing many of the concerns raised. They have clarified the incrementality of the contribution, provided additional details about how they handle discrete random variables, and explained the choice of approximations used in the paper.\n\n**Conclusion:**\n\nBased on the strengths and weaknesses of the paper, as well as the author responses, I believe that the paper has the potential to be a valuable contribution to the field of neural-symbolic AI. However, I also agree with some of the reviewers that the paper feels incremental and that the empirical evaluation could be improved.\n\n**Final Decision:** Accept\n\nI recommend accepting the paper for publication, subject to the authors addressing the remaining concerns raised by the reviewers. The authors have provided a clear and concise explanation of the language and its semantics, and the paper includes an implementation and experimental evaluation. While the paper may feel incremental, it still contributes to the field of neural-symbolic AI and provides a useful framework for researchers and practitioners."
    },
    {
      "paper_id": "WVZQa2QYJN",
      "source": "ICLR 2023",
      "true_decision": "Reject",
      "prediction": "Accept",
      "correct": false,
      "response": "After carefully analyzing the paper, reviewer comments, and author responses, I have the following detailed reasoning:\n\n**Strengths:**\n\n1. The paper presents a new and valuable dataset, RuDar, which fills a gap in the existing datasets for precipitation nowcasting.\n2. The dataset is well-described, and the authors provide a clear explanation of its characteristics and potential applications.\n3. The authors have made an effort to evaluate their dataset using several baseline models, including some recent and heavy-cost models like Earthformer.\n4. The paper is well-written, and the authors have addressed most of the reviewer comments in their response.\n\n**Weaknesses:**\n\n1. The paper lacks methodological novelties, as the authors have not proposed any new techniques or approaches for precipitation nowcasting.\n2. The evaluation metrics used in the paper are limited, and the authors have not explored other metrics that could provide a more comprehensive understanding of the models' performance.\n3. Some reviewers have raised concerns about the dataset's limitations, such as its coarse spatial resolution and the potential for domain adaptation issues.\n4. The paper could benefit from more detailed comparisons with other datasets and more extensive ablation studies to demonstrate the effectiveness of the RuDar dataset.\n\n**Author responses:**\n\nThe authors have addressed most of the reviewer comments in their response, providing additional information and clarifications. However, some concerns remain, such as the limited evaluation metrics and the potential for domain adaptation issues.\n\n**Conclusion:**\n\nWhile the paper presents a valuable dataset and has made an effort to evaluate it using several baseline models, it lacks methodological novelties and has some limitations. The authors have addressed most of the reviewer comments, but some concerns remain. Considering the paper's strengths and weaknesses, I believe that it is a good candidate for publication, but it requires some revisions to address the remaining concerns.\n\n**Final Decision:** Accept"
    }
  ]
}